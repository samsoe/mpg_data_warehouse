{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Update gridVeg Additional Species in BigQuery\n",
        "\n",
        "This notebook appends new additional species records to the BigQuery table from a CSV file stored in GCS.\n",
        "\n",
        "**Operation**: APPEND new rows (not replace entire table)\n",
        "\n",
        "## Requirements\n",
        "- Google Cloud credentials configured\n",
        "- Configuration file: copy `config.example.yml` to `config.yml` and fill in your values\n",
        "- Required packages: google-cloud-bigquery, google-cloud-storage, pandas, pyyaml\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import yaml\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from google.cloud import bigquery\n",
        "from google.cloud import storage\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"Libraries imported successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Configuration\n",
        "\n",
        "**TODO**: Add configuration section to config.yml for this table\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Configuration loaded successfully\n",
            "  CSV URL: gs://mpg-data-warehouse/gridVeg/src/2025/2025-09-18_gridVeg_...\n",
            "  Table ID: mpg-data-warehouse.vegetation_point_intercept_gridVeg.gridVeg_additional_species\n",
            "  Backup: gs://mpg-data-warehouse/gridVeg/bak\n"
          ]
        }
      ],
      "source": [
        "# Load configuration from YAML file\n",
        "config_path = Path(\"../config.yml\")\n",
        "\n",
        "if not config_path.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"Configuration file not found: {config_path}\\n\"\n",
        "        \"Please copy config.example.yml to config.yml and fill in your values.\"\n",
        "    )\n",
        "\n",
        "with open(config_path, 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "# Extract configuration values for gridVeg additional species\n",
        "# TODO: Update these config keys once added to config.yml\n",
        "GCS_CSV_URL = config['gridveg_additional_species']['gcs']['csv_url']\n",
        "BACKUP_BUCKET = config['gridveg_additional_species']['gcs'].get('backup_bucket')\n",
        "BACKUP_PREFIX = config['gridveg_additional_species']['gcs'].get('backup_prefix', 'backups/gridveg_additional_species')\n",
        "BQ_TABLE_ID = config['gridveg_additional_species']['bigquery']['table_id']\n",
        "BQ_PROJECT = config['gridveg_additional_species']['bigquery'].get('project')\n",
        "\n",
        "# Verify required config values\n",
        "if not GCS_CSV_URL or GCS_CSV_URL.startswith('gs://your-'):\n",
        "    raise ValueError(\"Please configure gridveg_additional_species.gcs.csv_url in config.yml\")\n",
        "if not BQ_TABLE_ID or 'your-project' in BQ_TABLE_ID:\n",
        "    raise ValueError(\"Please configure gridveg_additional_species.bigquery.table_id in config.yml\")\n",
        "\n",
        "print(\"✓ Configuration loaded successfully\")\n",
        "print(f\"  CSV URL: {GCS_CSV_URL[:60]}...\" if len(GCS_CSV_URL) > 60 else f\"  CSV URL: {GCS_CSV_URL}\")\n",
        "print(f\"  Table ID: {BQ_TABLE_ID}\")\n",
        "print(f\"  Backup: gs://{BACKUP_BUCKET}/{BACKUP_PREFIX}\" if BACKUP_BUCKET else \"  Backup: Not configured\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Clients initialized\n",
            "  Project: mpg-data-warehouse\n"
          ]
        }
      ],
      "source": [
        "# Initialize clients\n",
        "bq_client = bigquery.Client(project=BQ_PROJECT) if BQ_PROJECT else bigquery.Client()\n",
        "storage_client = storage.Client(project=BQ_PROJECT) if BQ_PROJECT else storage.Client()\n",
        "\n",
        "print(f\"✓ Clients initialized\")\n",
        "print(f\"  Project: {bq_client.project}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load CSV Data from GCS\n",
        "\n",
        "Read the source CSV file containing new additional species records.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading CSV from GCS...\n",
            "✓ CSV loaded successfully:\n",
            "  Rows: 390\n",
            "  Columns: ['Survey Data::__kp_Survey', 'Survey Data::_kf_Site', 'Survey Data::SurveyDate', 'Survey Data::SurveyYear', '_kf_Species_serial']\n",
            "\n",
            "First few rows:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survey Data::__kp_Survey</th>\n",
              "      <th>Survey Data::_kf_Site</th>\n",
              "      <th>Survey Data::SurveyDate</th>\n",
              "      <th>Survey Data::SurveyYear</th>\n",
              "      <th>_kf_Species_serial</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B45700C5-D391-4679-8579-217DCB1385A2</td>\n",
              "      <td>227</td>\n",
              "      <td>5/21/25</td>\n",
              "      <td>2025</td>\n",
              "      <td>492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B45700C5-D391-4679-8579-217DCB1385A2</td>\n",
              "      <td>227</td>\n",
              "      <td>5/21/25</td>\n",
              "      <td>2025</td>\n",
              "      <td>496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B45700C5-D391-4679-8579-217DCB1385A2</td>\n",
              "      <td>227</td>\n",
              "      <td>5/21/25</td>\n",
              "      <td>2025</td>\n",
              "      <td>230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B45700C5-D391-4679-8579-217DCB1385A2</td>\n",
              "      <td>227</td>\n",
              "      <td>5/21/25</td>\n",
              "      <td>2025</td>\n",
              "      <td>287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B45700C5-D391-4679-8579-217DCB1385A2</td>\n",
              "      <td>227</td>\n",
              "      <td>5/21/25</td>\n",
              "      <td>2025</td>\n",
              "      <td>303</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Survey Data::__kp_Survey  Survey Data::_kf_Site  \\\n",
              "0  B45700C5-D391-4679-8579-217DCB1385A2                    227   \n",
              "1  B45700C5-D391-4679-8579-217DCB1385A2                    227   \n",
              "2  B45700C5-D391-4679-8579-217DCB1385A2                    227   \n",
              "3  B45700C5-D391-4679-8579-217DCB1385A2                    227   \n",
              "4  B45700C5-D391-4679-8579-217DCB1385A2                    227   \n",
              "\n",
              "  Survey Data::SurveyDate  Survey Data::SurveyYear  _kf_Species_serial  \n",
              "0                 5/21/25                     2025                 492  \n",
              "1                 5/21/25                     2025                 496  \n",
              "2                 5/21/25                     2025                 230  \n",
              "3                 5/21/25                     2025                 287  \n",
              "4                 5/21/25                     2025                 303  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Read CSV from GCS (new data)\n",
        "print(\"Reading CSV from GCS...\")\n",
        "df_new = pd.read_csv(GCS_CSV_URL)\n",
        "\n",
        "print(f\"✓ CSV loaded successfully:\")\n",
        "print(f\"  Rows: {len(df_new)}\")\n",
        "print(f\"  Columns: {list(df_new.columns)}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "df_new.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transform CSV Data\n",
        "\n",
        "Apply schema transformations to match BigQuery table:\n",
        "- Rename columns to match destination schema\n",
        "- Convert date format from mm/dd/yy to ISO format (YYYY-MM-DD)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Column mapping:\n",
            "  Survey Data::__kp_Survey            → survey_ID\n",
            "  Survey Data::_kf_Site               → grid_point\n",
            "  Survey Data::SurveyDate             → date\n",
            "  Survey Data::SurveyYear             → year\n",
            "  _kf_Species_serial                  → key_plant_species\n"
          ]
        }
      ],
      "source": [
        "# Define column mapping from CSV to BigQuery\n",
        "column_mapping = {\n",
        "    'Survey Data::__kp_Survey': 'survey_ID',\n",
        "    'Survey Data::_kf_Site': 'grid_point',\n",
        "    'Survey Data::SurveyDate': 'date',\n",
        "    'Survey Data::SurveyYear': 'year',\n",
        "    '_kf_Species_serial': 'key_plant_species'\n",
        "}\n",
        "\n",
        "print(\"Column mapping:\")\n",
        "for csv_col, bq_col in column_mapping.items():\n",
        "    print(f\"  {csv_col:35s} → {bq_col}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ CSV columns match expected schema\n",
            "\n",
            "CSV columns: ['Survey Data::__kp_Survey', 'Survey Data::_kf_Site', 'Survey Data::SurveyDate', 'Survey Data::SurveyYear', '_kf_Species_serial']\n"
          ]
        }
      ],
      "source": [
        "# Verify CSV columns match expected schema\n",
        "expected_csv_columns = set(column_mapping.keys())\n",
        "actual_csv_columns = set(df_new.columns)\n",
        "\n",
        "if actual_csv_columns == expected_csv_columns:\n",
        "    print(\"✓ CSV columns match expected schema\")\n",
        "else:\n",
        "    print(\"⚠ CSV column differences detected:\")\n",
        "    if actual_csv_columns - expected_csv_columns:\n",
        "        print(f\"  Unexpected columns: {actual_csv_columns - expected_csv_columns}\")\n",
        "    if expected_csv_columns - actual_csv_columns:\n",
        "        print(f\"  Missing columns: {expected_csv_columns - actual_csv_columns}\")\n",
        "    \n",
        "print(f\"\\nCSV columns: {list(df_new.columns)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Columns renamed\n",
            "  Transformed columns: ['survey_ID', 'grid_point', 'date', 'year', 'key_plant_species']\n"
          ]
        }
      ],
      "source": [
        "# Apply transformation: rename columns\n",
        "df_transformed = df_new.copy()\n",
        "df_transformed = df_transformed.rename(columns=column_mapping)\n",
        "\n",
        "print(\"✓ Columns renamed\")\n",
        "print(f\"  Transformed columns: {list(df_transformed.columns)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Date format converted to date type\n",
            "  Sample dates: [datetime.date(2025, 5, 21), datetime.date(2025, 5, 21), datetime.date(2025, 5, 21), datetime.date(2025, 5, 21), datetime.date(2025, 5, 21)]\n"
          ]
        }
      ],
      "source": [
        "# Convert date from m/d/yy to proper datetime/date format\n",
        "# Explicitly specify format to avoid parsing warnings and ensure consistency\n",
        "# Note: %y handles 2-digit years (00-68 = 2000-2068, 69-99 = 1969-1999)\n",
        "df_transformed['date'] = pd.to_datetime(df_transformed['date'], format='%m/%d/%y').dt.date\n",
        "\n",
        "print(\"✓ Date format converted to date type\")\n",
        "print(f\"  Sample dates: {df_transformed['date'].head().tolist()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transformed Data Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 390 entries, 0 to 389\n",
            "Data columns (total 5 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   survey_ID          390 non-null    object\n",
            " 1   grid_point         390 non-null    int64 \n",
            " 2   date               390 non-null    object\n",
            " 3   year               390 non-null    int64 \n",
            " 4   key_plant_species  390 non-null    int64 \n",
            "dtypes: int64(3), object(2)\n",
            "memory usage: 15.4+ KB\n",
            "\n",
            "Transformed data preview:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survey_ID</th>\n",
              "      <th>grid_point</th>\n",
              "      <th>date</th>\n",
              "      <th>year</th>\n",
              "      <th>key_plant_species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B45700C5-D391-4679-8579-217DCB1385A2</td>\n",
              "      <td>227</td>\n",
              "      <td>2025-05-21</td>\n",
              "      <td>2025</td>\n",
              "      <td>492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B45700C5-D391-4679-8579-217DCB1385A2</td>\n",
              "      <td>227</td>\n",
              "      <td>2025-05-21</td>\n",
              "      <td>2025</td>\n",
              "      <td>496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B45700C5-D391-4679-8579-217DCB1385A2</td>\n",
              "      <td>227</td>\n",
              "      <td>2025-05-21</td>\n",
              "      <td>2025</td>\n",
              "      <td>230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B45700C5-D391-4679-8579-217DCB1385A2</td>\n",
              "      <td>227</td>\n",
              "      <td>2025-05-21</td>\n",
              "      <td>2025</td>\n",
              "      <td>287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B45700C5-D391-4679-8579-217DCB1385A2</td>\n",
              "      <td>227</td>\n",
              "      <td>2025-05-21</td>\n",
              "      <td>2025</td>\n",
              "      <td>303</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              survey_ID  grid_point        date  year  \\\n",
              "0  B45700C5-D391-4679-8579-217DCB1385A2         227  2025-05-21  2025   \n",
              "1  B45700C5-D391-4679-8579-217DCB1385A2         227  2025-05-21  2025   \n",
              "2  B45700C5-D391-4679-8579-217DCB1385A2         227  2025-05-21  2025   \n",
              "3  B45700C5-D391-4679-8579-217DCB1385A2         227  2025-05-21  2025   \n",
              "4  B45700C5-D391-4679-8579-217DCB1385A2         227  2025-05-21  2025   \n",
              "\n",
              "   key_plant_species  \n",
              "0                492  \n",
              "1                496  \n",
              "2                230  \n",
              "3                287  \n",
              "4                303  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display transformed data info\n",
        "print(\"Transformed Data Info:\")\n",
        "df_transformed.info()\n",
        "print(f\"\\nTransformed data preview:\")\n",
        "df_transformed.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Read Existing BigQuery Table\n",
        "\n",
        "Load the current data from BigQuery to compare with the new data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading existing data from mpg-data-warehouse.vegetation_point_intercept_gridVeg.gridVeg_additional_species...\n",
            "✓ Existing table loaded:\n",
            "  Rows: 13662\n",
            "  Columns: ['survey_ID', 'grid_point', 'date', 'year', 'key_plant_species']\n",
            "\n",
            "Existing data preview:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survey_ID</th>\n",
              "      <th>grid_point</th>\n",
              "      <th>date</th>\n",
              "      <th>year</th>\n",
              "      <th>key_plant_species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>308</td>\n",
              "      <td>324</td>\n",
              "      <td>2011-05-10</td>\n",
              "      <td>2011</td>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>308</td>\n",
              "      <td>324</td>\n",
              "      <td>2011-05-10</td>\n",
              "      <td>2011</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>308</td>\n",
              "      <td>324</td>\n",
              "      <td>2011-05-10</td>\n",
              "      <td>2011</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>308</td>\n",
              "      <td>324</td>\n",
              "      <td>2011-05-10</td>\n",
              "      <td>2011</td>\n",
              "      <td>82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>308</td>\n",
              "      <td>324</td>\n",
              "      <td>2011-05-10</td>\n",
              "      <td>2011</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  survey_ID  grid_point        date  year  key_plant_species\n",
              "0       308         324  2011-05-10  2011                 69\n",
              "1       308         324  2011-05-10  2011                 72\n",
              "2       308         324  2011-05-10  2011                  5\n",
              "3       308         324  2011-05-10  2011                 82\n",
              "4       308         324  2011-05-10  2011                 75"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Read existing data from BigQuery\n",
        "print(f\"Reading existing data from {BQ_TABLE_ID}...\")\n",
        "query = f\"SELECT * FROM `{BQ_TABLE_ID}`\"\n",
        "\n",
        "try:\n",
        "    df_existing = bq_client.query(query).to_dataframe()\n",
        "    print(f\"✓ Existing table loaded:\")\n",
        "    print(f\"  Rows: {len(df_existing)}\")\n",
        "    print(f\"  Columns: {list(df_existing.columns)}\")\n",
        "    print(f\"\\nExisting data preview:\")\n",
        "    display(df_existing.head())\n",
        "except Exception as e:\n",
        "    print(f\"⚠ Error reading table: {e}\")\n",
        "    print(\"  This may be expected if the table doesn't exist yet.\")\n",
        "    df_existing = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Existing Data Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 13662 entries, 0 to 13661\n",
            "Data columns (total 5 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   survey_ID          13662 non-null  object\n",
            " 1   grid_point         13662 non-null  Int64 \n",
            " 2   date               13662 non-null  dbdate\n",
            " 3   year               13662 non-null  Int64 \n",
            " 4   key_plant_species  13648 non-null  Int64 \n",
            "dtypes: Int64(3), dbdate(1), object(1)\n",
            "memory usage: 573.8+ KB\n"
          ]
        }
      ],
      "source": [
        "# Display existing data info (if available)\n",
        "if df_existing is not None:\n",
        "    print(\"Existing Data Info:\")\n",
        "    df_existing.info()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compare New vs Existing Data\n",
        "\n",
        "Identify which rows in the new data are not already in the existing table.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Comparison Summary ===\n",
            "\n",
            "Row count:\n",
            "  Existing: 13662\n",
            "  New CSV:  390\n",
            "\n",
            "✓ Columns match (5 columns)\n",
            "\n",
            "Columns: ['survey_ID', 'grid_point', 'date', 'year', 'key_plant_species']\n"
          ]
        }
      ],
      "source": [
        "# Compare datasets\n",
        "if df_existing is not None:\n",
        "    print(\"=== Comparison Summary ===\\n\")\n",
        "    \n",
        "    # Row count comparison\n",
        "    print(f\"Row count:\")\n",
        "    print(f\"  Existing: {len(df_existing)}\")\n",
        "    print(f\"  New CSV:  {len(df_transformed)}\")\n",
        "    \n",
        "    # Column comparison\n",
        "    existing_cols = set(df_existing.columns)\n",
        "    new_cols = set(df_transformed.columns)\n",
        "    \n",
        "    if existing_cols == new_cols:\n",
        "        print(f\"\\n✓ Columns match ({len(new_cols)} columns)\")\n",
        "    else:\n",
        "        print(\"\\n⚠ Column differences detected:\")\n",
        "        if new_cols - existing_cols:\n",
        "            print(f\"  New columns: {new_cols - existing_cols}\")\n",
        "        if existing_cols - new_cols:\n",
        "            print(f\"  Missing columns: {existing_cols - new_cols}\")\n",
        "    \n",
        "    print(f\"\\nColumns: {list(df_transformed.columns)}\")\n",
        "else:\n",
        "    print(\"No existing data to compare - this will be a new table creation.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Found 390 new records to append\n",
            "\n",
            "New records by year:\n",
            "  2025: 390 records\n",
            "\n",
            "Sample of new records:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survey_ID</th>\n",
              "      <th>grid_point</th>\n",
              "      <th>date</th>\n",
              "      <th>year</th>\n",
              "      <th>key_plant_species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B45700C5-D391-4679-8579-217DCB1385A2</td>\n",
              "      <td>227</td>\n",
              "      <td>2025-05-21</td>\n",
              "      <td>2025</td>\n",
              "      <td>492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B45700C5-D391-4679-8579-217DCB1385A2</td>\n",
              "      <td>227</td>\n",
              "      <td>2025-05-21</td>\n",
              "      <td>2025</td>\n",
              "      <td>496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B45700C5-D391-4679-8579-217DCB1385A2</td>\n",
              "      <td>227</td>\n",
              "      <td>2025-05-21</td>\n",
              "      <td>2025</td>\n",
              "      <td>230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B45700C5-D391-4679-8579-217DCB1385A2</td>\n",
              "      <td>227</td>\n",
              "      <td>2025-05-21</td>\n",
              "      <td>2025</td>\n",
              "      <td>287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B45700C5-D391-4679-8579-217DCB1385A2</td>\n",
              "      <td>227</td>\n",
              "      <td>2025-05-21</td>\n",
              "      <td>2025</td>\n",
              "      <td>303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>C0BD2A75-FF0B-48DC-BB9D-941267BF5838</td>\n",
              "      <td>190</td>\n",
              "      <td>2025-05-21</td>\n",
              "      <td>2025</td>\n",
              "      <td>320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>C0BD2A75-FF0B-48DC-BB9D-941267BF5838</td>\n",
              "      <td>190</td>\n",
              "      <td>2025-05-21</td>\n",
              "      <td>2025</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>C0BD2A75-FF0B-48DC-BB9D-941267BF5838</td>\n",
              "      <td>190</td>\n",
              "      <td>2025-05-21</td>\n",
              "      <td>2025</td>\n",
              "      <td>156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>C0BD2A75-FF0B-48DC-BB9D-941267BF5838</td>\n",
              "      <td>190</td>\n",
              "      <td>2025-05-21</td>\n",
              "      <td>2025</td>\n",
              "      <td>388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>C0BD2A75-FF0B-48DC-BB9D-941267BF5838</td>\n",
              "      <td>190</td>\n",
              "      <td>2025-05-21</td>\n",
              "      <td>2025</td>\n",
              "      <td>262</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              survey_ID  grid_point        date  year  \\\n",
              "0  B45700C5-D391-4679-8579-217DCB1385A2         227  2025-05-21  2025   \n",
              "1  B45700C5-D391-4679-8579-217DCB1385A2         227  2025-05-21  2025   \n",
              "2  B45700C5-D391-4679-8579-217DCB1385A2         227  2025-05-21  2025   \n",
              "3  B45700C5-D391-4679-8579-217DCB1385A2         227  2025-05-21  2025   \n",
              "4  B45700C5-D391-4679-8579-217DCB1385A2         227  2025-05-21  2025   \n",
              "5  C0BD2A75-FF0B-48DC-BB9D-941267BF5838         190  2025-05-21  2025   \n",
              "6  C0BD2A75-FF0B-48DC-BB9D-941267BF5838         190  2025-05-21  2025   \n",
              "7  C0BD2A75-FF0B-48DC-BB9D-941267BF5838         190  2025-05-21  2025   \n",
              "8  C0BD2A75-FF0B-48DC-BB9D-941267BF5838         190  2025-05-21  2025   \n",
              "9  C0BD2A75-FF0B-48DC-BB9D-941267BF5838         190  2025-05-21  2025   \n",
              "\n",
              "   key_plant_species  \n",
              "0                492  \n",
              "1                496  \n",
              "2                230  \n",
              "3                287  \n",
              "4                303  \n",
              "5                320  \n",
              "6                 67  \n",
              "7                156  \n",
              "8                388  \n",
              "9                262  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Identify new records (not in existing table)\n",
        "# Use combination of survey_ID + key_plant_species as the composite key\n",
        "if df_existing is not None:\n",
        "    # Create composite key for both dataframes\n",
        "    df_existing['_composite_key'] = df_existing['survey_ID'].astype(str) + '_' + df_existing['key_plant_species'].astype(str)\n",
        "    df_transformed['_composite_key'] = df_transformed['survey_ID'].astype(str) + '_' + df_transformed['key_plant_species'].astype(str)\n",
        "    \n",
        "    existing_keys = set(df_existing['_composite_key'])\n",
        "    new_keys = set(df_transformed['_composite_key'])\n",
        "    \n",
        "    # Find records in new data that aren't in existing\n",
        "    keys_to_append = new_keys - existing_keys\n",
        "    \n",
        "    if keys_to_append:\n",
        "        df_to_append = df_transformed[df_transformed['_composite_key'].isin(keys_to_append)].copy()\n",
        "        # Drop the temporary composite key column\n",
        "        df_to_append = df_to_append.drop(columns=['_composite_key'])\n",
        "        \n",
        "        print(f\"✓ Found {len(df_to_append)} new records to append\")\n",
        "        \n",
        "        # Show year breakdown of new records\n",
        "        print(f\"\\nNew records by year:\")\n",
        "        year_counts = df_to_append['year'].value_counts().sort_index()\n",
        "        for year, count in year_counts.items():\n",
        "            print(f\"  {year}: {count} records\")\n",
        "        \n",
        "        print(f\"\\nSample of new records:\")\n",
        "        display(df_to_append.head(10))\n",
        "    else:\n",
        "        df_to_append = None\n",
        "        print(\"⚠ No new records found - all records already exist in table\")\n",
        "        print(\"  Nothing to append.\")\n",
        "    \n",
        "    # Check for any duplicates\n",
        "    duplicate_keys = existing_keys & new_keys\n",
        "    if duplicate_keys:\n",
        "        print(f\"\\n⚠ Warning: {len(duplicate_keys)} records already exist in table\")\n",
        "        print(f\"  These will be skipped during append.\")\n",
        "        if len(duplicate_keys) <= 10:\n",
        "            df_existing_temp = df_existing[df_existing['_composite_key'].isin(list(duplicate_keys)[:10])]\n",
        "            print(f\"\\n  Sample duplicate records (survey_ID, species):\")\n",
        "            for _, row in df_existing_temp[['survey_ID', 'key_plant_species']].head(10).iterrows():\n",
        "                print(f\"    {row['survey_ID']}, {row['key_plant_species']}\")\n",
        "    \n",
        "    # Clean up temporary column from df_existing and df_transformed\n",
        "    df_existing = df_existing.drop(columns=['_composite_key'])\n",
        "    df_transformed = df_transformed.drop(columns=['_composite_key'])\n",
        "else:\n",
        "    # No existing table, so all records are new\n",
        "    df_to_append = df_transformed.copy()\n",
        "    print(f\"✓ No existing table - will create new table with {len(df_to_append)} records\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Backup Existing Table\n",
        "\n",
        "Before making any changes, create a backup of the existing table to GCS.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating backup of existing table...\n",
            "  Destination: gs://mpg-data-warehouse/gridVeg/bak/20251031_102839/*.csv\n",
            "✓ Backup completed successfully\n",
            "  Files: gs://mpg-data-warehouse/gridVeg/bak/20251031_102839/*.csv\n"
          ]
        }
      ],
      "source": [
        "# Backup existing table to GCS\n",
        "if df_existing is not None and BACKUP_BUCKET and df_to_append is not None:\n",
        "    # Generate backup path with timestamp\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    backup_path = f\"gs://{BACKUP_BUCKET}/{BACKUP_PREFIX}/{timestamp}/*.csv\"\n",
        "    \n",
        "    print(f\"Creating backup of existing table...\")\n",
        "    print(f\"  Destination: {backup_path}\")\n",
        "    \n",
        "    # Export table to GCS\n",
        "    extract_job = bq_client.extract_table(\n",
        "        BQ_TABLE_ID,\n",
        "        backup_path,\n",
        "        location=\"US\"\n",
        "    )\n",
        "    \n",
        "    extract_job.result()  # Wait for job to complete\n",
        "    \n",
        "    print(f\"✓ Backup completed successfully\")\n",
        "    print(f\"  Files: {backup_path}\")\n",
        "elif df_existing is None:\n",
        "    print(\"⚠ No existing table to backup (table doesn't exist yet)\")\n",
        "elif not BACKUP_BUCKET:\n",
        "    print(\"⚠ Backup bucket not configured in config.yml\")\n",
        "    print(\"  Set 'gridveg_additional_species.gcs.backup_bucket' to enable automatic backups\")\n",
        "elif df_to_append is None:\n",
        "    print(\"⚠ No new records to append, skipping backup\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Append New Records to BigQuery\n",
        "\n",
        "⚠️ **IMPORTANT**: This will APPEND new rows to the existing table (not replace).\n",
        "\n",
        "Review the comparison above before proceeding.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "APPENDING TO BIGQUERY TABLE\n",
            "============================================================\n",
            "\n",
            "Table: mpg-data-warehouse.vegetation_point_intercept_gridVeg.gridVeg_additional_species\n",
            "Rows to append: 390\n",
            "Mode: WRITE_APPEND (add to existing table)\n",
            "\n",
            "Starting append at 2025-10-31 10:28:48...\n",
            "\n",
            "✓ Append completed at 2025-10-31 10:28:52\n",
            "  Rows appended: 390\n",
            "  Job ID: d124a00c-280b-43b1-9c2c-aa62d246f359\n"
          ]
        }
      ],
      "source": [
        "# Append new records to BigQuery\n",
        "if df_to_append is not None and len(df_to_append) > 0:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"APPENDING TO BIGQUERY TABLE\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"\\nTable: {BQ_TABLE_ID}\")\n",
        "    print(f\"Rows to append: {len(df_to_append)}\")\n",
        "    print(f\"Mode: WRITE_APPEND (add to existing table)\")\n",
        "    print(f\"\\nStarting append at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}...\")\n",
        "    \n",
        "    # Configure job to append to existing table\n",
        "    job_config = bigquery.LoadJobConfig(\n",
        "        write_disposition=\"WRITE_APPEND\"  # Append to existing table\n",
        "    )\n",
        "    \n",
        "    # Load dataframe to BigQuery\n",
        "    load_job = bq_client.load_table_from_dataframe(\n",
        "        df_to_append,\n",
        "        BQ_TABLE_ID,\n",
        "        job_config=job_config\n",
        "    )\n",
        "    \n",
        "    # Wait for job to complete\n",
        "    load_job.result()\n",
        "    \n",
        "    print(f\"\\n✓ Append completed at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "    print(f\"  Rows appended: {load_job.output_rows}\")\n",
        "    print(f\"  Job ID: {load_job.job_id}\")\n",
        "else:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"NO RECORDS TO APPEND\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"\\nNo new records found or no records to append.\")\n",
        "    print(\"Table remains unchanged.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Verify Append\n",
        "\n",
        "Read back the table to verify the append was successful.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Verifying append...\n",
            "\n",
            "✓ Verification complete\n",
            "  Rows in table: 14052\n",
            "  Columns: ['survey_ID', 'grid_point', 'date', 'year', 'key_plant_species']\n",
            "\n",
            "Records by year:\n",
            "  2011: 4043 records\n",
            "  2012: 1747 records\n",
            "  2013: 209 records\n",
            "  2015: 485 records\n",
            "  2016: 4906 records\n",
            "  2017: 39 records\n",
            "  2021: 1238 records\n",
            "  2022: 454 records\n",
            "  2023: 267 records\n",
            "  2024: 274 records\n",
            "  2025: 390 records\n",
            "\n",
            "Updated table preview:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survey_ID</th>\n",
              "      <th>grid_point</th>\n",
              "      <th>date</th>\n",
              "      <th>year</th>\n",
              "      <th>key_plant_species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14042</th>\n",
              "      <td>E71C66DF-7C7A-4834-8034-5731CDDE84C9</td>\n",
              "      <td>70</td>\n",
              "      <td>2024-07-10</td>\n",
              "      <td>2024</td>\n",
              "      <td>334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14043</th>\n",
              "      <td>E71C66DF-7C7A-4834-8034-5731CDDE84C9</td>\n",
              "      <td>70</td>\n",
              "      <td>2024-07-10</td>\n",
              "      <td>2024</td>\n",
              "      <td>558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14044</th>\n",
              "      <td>E71C66DF-7C7A-4834-8034-5731CDDE84C9</td>\n",
              "      <td>70</td>\n",
              "      <td>2024-07-10</td>\n",
              "      <td>2024</td>\n",
              "      <td>135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14045</th>\n",
              "      <td>11BCE714-4E58-4F75-8238-323BB5D2616C</td>\n",
              "      <td>420</td>\n",
              "      <td>2024-07-11</td>\n",
              "      <td>2024</td>\n",
              "      <td>308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14046</th>\n",
              "      <td>11BCE714-4E58-4F75-8238-323BB5D2616C</td>\n",
              "      <td>420</td>\n",
              "      <td>2024-07-11</td>\n",
              "      <td>2024</td>\n",
              "      <td>125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14047</th>\n",
              "      <td>11BCE714-4E58-4F75-8238-323BB5D2616C</td>\n",
              "      <td>420</td>\n",
              "      <td>2024-07-11</td>\n",
              "      <td>2024</td>\n",
              "      <td>84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14048</th>\n",
              "      <td>11BCE714-4E58-4F75-8238-323BB5D2616C</td>\n",
              "      <td>420</td>\n",
              "      <td>2024-07-11</td>\n",
              "      <td>2024</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14049</th>\n",
              "      <td>11BCE714-4E58-4F75-8238-323BB5D2616C</td>\n",
              "      <td>420</td>\n",
              "      <td>2024-07-11</td>\n",
              "      <td>2024</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14050</th>\n",
              "      <td>11BCE714-4E58-4F75-8238-323BB5D2616C</td>\n",
              "      <td>420</td>\n",
              "      <td>2024-07-11</td>\n",
              "      <td>2024</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14051</th>\n",
              "      <td>11BCE714-4E58-4F75-8238-323BB5D2616C</td>\n",
              "      <td>420</td>\n",
              "      <td>2024-07-11</td>\n",
              "      <td>2024</td>\n",
              "      <td>113</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  survey_ID  grid_point        date  year  \\\n",
              "14042  E71C66DF-7C7A-4834-8034-5731CDDE84C9          70  2024-07-10  2024   \n",
              "14043  E71C66DF-7C7A-4834-8034-5731CDDE84C9          70  2024-07-10  2024   \n",
              "14044  E71C66DF-7C7A-4834-8034-5731CDDE84C9          70  2024-07-10  2024   \n",
              "14045  11BCE714-4E58-4F75-8238-323BB5D2616C         420  2024-07-11  2024   \n",
              "14046  11BCE714-4E58-4F75-8238-323BB5D2616C         420  2024-07-11  2024   \n",
              "14047  11BCE714-4E58-4F75-8238-323BB5D2616C         420  2024-07-11  2024   \n",
              "14048  11BCE714-4E58-4F75-8238-323BB5D2616C         420  2024-07-11  2024   \n",
              "14049  11BCE714-4E58-4F75-8238-323BB5D2616C         420  2024-07-11  2024   \n",
              "14050  11BCE714-4E58-4F75-8238-323BB5D2616C         420  2024-07-11  2024   \n",
              "14051  11BCE714-4E58-4F75-8238-323BB5D2616C         420  2024-07-11  2024   \n",
              "\n",
              "       key_plant_species  \n",
              "14042                334  \n",
              "14043                558  \n",
              "14044                135  \n",
              "14045                308  \n",
              "14046                125  \n",
              "14047                 84  \n",
              "14048                 20  \n",
              "14049                 90  \n",
              "14050                  5  \n",
              "14051                113  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Read updated table\n",
        "print(\"Verifying append...\")\n",
        "query = f\"SELECT * FROM `{BQ_TABLE_ID}`\"\n",
        "df_updated = bq_client.query(query).to_dataframe()\n",
        "\n",
        "print(f\"\\n✓ Verification complete\")\n",
        "print(f\"  Rows in table: {len(df_updated)}\")\n",
        "print(f\"  Columns: {list(df_updated.columns)}\")\n",
        "\n",
        "# Show records by year\n",
        "print(f\"\\nRecords by year:\")\n",
        "year_counts = df_updated['year'].value_counts().sort_index()\n",
        "for year, count in year_counts.items():\n",
        "    print(f\"  {year}: {count} records\")\n",
        "\n",
        "print(f\"\\nUpdated table preview:\")\n",
        "df_updated.tail(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data integrity check:\n",
            "  Previous rows:   13662\n",
            "  Rows appended:   390\n",
            "  Expected total:  14052\n",
            "  Actual total:    14052\n",
            "\n",
            "✓ Row count verified - all 390 new rows successfully appended\n"
          ]
        }
      ],
      "source": [
        "# Verify row counts\n",
        "if df_to_append is not None and len(df_to_append) > 0:\n",
        "    expected_rows = len(df_existing) + len(df_to_append) if df_existing is not None else len(df_to_append)\n",
        "    actual_rows = len(df_updated)\n",
        "    \n",
        "    print(\"Data integrity check:\")\n",
        "    if df_existing is not None:\n",
        "        print(f\"  Previous rows:   {len(df_existing)}\")\n",
        "        print(f\"  Rows appended:   {len(df_to_append)}\")\n",
        "        print(f\"  Expected total:  {expected_rows}\")\n",
        "        print(f\"  Actual total:    {actual_rows}\")\n",
        "    else:\n",
        "        print(f\"  Rows written:    {len(df_to_append)}\")\n",
        "        print(f\"  Rows in table:   {actual_rows}\")\n",
        "    \n",
        "    if expected_rows == actual_rows:\n",
        "        print(f\"\\n✓ Row count verified - all {len(df_to_append)} new rows successfully appended\")\n",
        "    else:\n",
        "        print(f\"\\n⚠ Row count mismatch!\")\n",
        "        print(f\"  Expected: {expected_rows}\")\n",
        "        print(f\"  Actual:   {actual_rows}\")\n",
        "        print(f\"  Difference: {actual_rows - expected_rows}\")\n",
        "else:\n",
        "    print(\"No new records were appended.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary Report\n",
        "\n",
        "Complete summary of the append operation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "GRIDVEG ADDITIONAL SPECIES APPEND SUMMARY\n",
            "============================================================\n",
            "\n",
            "📅 Timestamp: 2025-10-31 10:29:26\n",
            "\n",
            "📂 Source:\n",
            "  CSV: 2025-09-18_gridVeg_additional_species_SOURCE.csv\n",
            "  Location: gs://mpg-data-warehouse/gridVeg/src/2025\n",
            "\n",
            "🎯 Target:\n",
            "  Table: mpg-data-warehouse.vegetation_point_intercept_gridVeg.gridVeg_additional_species\n",
            "  Project: mpg-data-warehouse\n",
            "\n",
            "📊 Data Changes:\n",
            "  Previous rows: 13662\n",
            "  New rows:      14052\n",
            "  Rows appended: +390\n",
            "\n",
            "  Appended records by year:\n",
            "    2025: 390 records\n",
            "\n",
            "🔄 Transformations Applied:\n",
            "  ✓ Renamed 5 columns to match BigQuery schema\n",
            "  ✓ Converted date format to ISO (YYYY-MM-DD)\n",
            "  ✓ Used composite key (survey_ID + key_plant_species) for duplicate detection\n",
            "\n",
            "💾 Backup:\n",
            "  Location: gs://mpg-data-warehouse/gridVeg/bak/\n",
            "  Status: ✓ Created before append\n",
            "\n",
            "✅ Append completed successfully!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Generate summary report\n",
        "print(\"=\" * 60)\n",
        "print(\"GRIDVEG ADDITIONAL SPECIES APPEND SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\n📅 Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "print(f\"\\n📂 Source:\")\n",
        "print(f\"  CSV: {GCS_CSV_URL.split('/')[-1]}\")\n",
        "print(f\"  Location: {'/'.join(GCS_CSV_URL.split('/')[:-1])}\")\n",
        "\n",
        "print(f\"\\n🎯 Target:\")\n",
        "print(f\"  Table: {BQ_TABLE_ID}\")\n",
        "print(f\"  Project: {bq_client.project}\")\n",
        "\n",
        "print(f\"\\n📊 Data Changes:\")\n",
        "if df_existing is not None:\n",
        "    print(f\"  Previous rows: {len(df_existing)}\")\n",
        "    print(f\"  New rows:      {len(df_updated)}\")\n",
        "    print(f\"  Rows appended: {len(df_updated) - len(df_existing):+d}\")\n",
        "    \n",
        "    if df_to_append is not None and len(df_to_append) > 0:\n",
        "        print(f\"\\n  Appended records by year:\")\n",
        "        year_counts = df_to_append['year'].value_counts().sort_index()\n",
        "        for year, count in year_counts.items():\n",
        "            print(f\"    {year}: {count} records\")\n",
        "else:\n",
        "    print(f\"  New table created with {len(df_updated)} rows\")\n",
        "\n",
        "print(f\"\\n🔄 Transformations Applied:\")\n",
        "print(f\"  ✓ Renamed {len(column_mapping)} columns to match BigQuery schema\")\n",
        "print(f\"  ✓ Converted date format to ISO (YYYY-MM-DD)\")\n",
        "print(f\"  ✓ Used composite key (survey_ID + key_plant_species) for duplicate detection\")\n",
        "\n",
        "if BACKUP_BUCKET and df_existing is not None and df_to_append is not None and len(df_to_append) > 0:\n",
        "    print(f\"\\n💾 Backup:\")\n",
        "    print(f\"  Location: gs://{BACKUP_BUCKET}/{BACKUP_PREFIX}/\")\n",
        "    print(f\"  Status: ✓ Created before append\")\n",
        "\n",
        "if df_to_append is not None and len(df_to_append) > 0:\n",
        "    print(f\"\\n✅ Append completed successfully!\")\n",
        "else:\n",
        "    print(f\"\\n✅ No changes needed - table is up to date!\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Rollback Instructions (If Needed)\n",
        "\n",
        "If you need to rollback to the previous version, use the backup created at the beginning of this notebook.\n",
        "\n",
        "```python\n",
        "# To rollback, first identify and delete the appended rows:\n",
        "# Create composite keys for filtering\n",
        "# df_rollback = df_updated.copy()\n",
        "# df_rollback['_composite_key'] = df_rollback['survey_ID'].astype(str) + '_' + df_rollback['key_plant_species'].astype(str)\n",
        "# keys_to_remove = set([row['survey_ID'] + '_' + str(row['key_plant_species']) for _, row in df_to_append.iterrows()])\n",
        "# df_rollback = df_rollback[~df_rollback['_composite_key'].isin(keys_to_remove)].drop(columns=['_composite_key'])\n",
        "# job_config = bigquery.LoadJobConfig(write_disposition=\"WRITE_TRUNCATE\")\n",
        "# bq_client.load_table_from_dataframe(df_rollback, BQ_TABLE_ID, job_config=job_config)\n",
        "\n",
        "# Or restore from backup:\n",
        "# backup_path = \"gs://BACKUP_BUCKET/BACKUP_PREFIX/TIMESTAMP/*.csv\"\n",
        "# df_backup = pd.read_csv(backup_path)\n",
        "# job_config = bigquery.LoadJobConfig(write_disposition=\"WRITE_TRUNCATE\")\n",
        "# bq_client.load_table_from_dataframe(df_backup, BQ_TABLE_ID, job_config=job_config)\n",
        "```\n",
        "\n",
        "The backup location was printed in the backup cell above.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "gcloud",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
