{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Update gridVeg Point Intercepts in BigQuery\n",
        "\n",
        "This notebook appends new point intercept data to BigQuery tables from a CSV file stored in GCS.\n",
        "\n",
        "**Operation**: APPEND new rows (not replace entire table)\n",
        "\n",
        "**Target Tables**:\n",
        "- `gridVeg_point_intercept_vegetation` - vegetation intercept data (4 height layers)\n",
        "- `gridVeg_point_intercept_ground` - ground cover intercept data\n",
        "\n",
        "## Requirements\n",
        "- Google Cloud credentials configured\n",
        "- Configuration file: copy `config.example.yml` to `config.yml` and fill in your values\n",
        "- Required packages: google-cloud-bigquery, google-cloud-storage, pandas, pyyaml\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import yaml\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from google.cloud import bigquery\n",
        "from google.cloud import storage\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"Libraries imported successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Configuration loaded successfully\n",
            "  CSV URL: gs://mpg-data-warehouse/gridVeg/src/2025/2025-09-18_gridVeg_...\n",
            "  Vegetation Table: mpg-data-warehouse.vegetation_point_intercept_gridVeg.gridVeg_point_intercept_vegetation\n",
            "  Ground Table: mpg-data-warehouse.vegetation_point_intercept_gridVeg.gridVeg_point_intercept_ground\n",
            "  Backup: gs://mpg-data-warehouse/gridVeg/bak\n"
          ]
        }
      ],
      "source": [
        "# Load configuration from YAML file\n",
        "config_path = Path(\"../config.yml\")\n",
        "\n",
        "if not config_path.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"Configuration file not found: {config_path}\\n\"\n",
        "        \"Please copy config.example.yml to config.yml and fill in your values.\"\n",
        "    )\n",
        "\n",
        "with open(config_path, 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "# Extract configuration values for gridVeg point intercepts\n",
        "GCS_CSV_URL = config['gridveg_point_intercepts']['gcs']['csv_url']\n",
        "BACKUP_BUCKET = config['gridveg_point_intercepts']['gcs'].get('backup_bucket')\n",
        "BACKUP_PREFIX = config['gridveg_point_intercepts']['gcs'].get('backup_prefix', 'backups/gridveg_point_intercepts')\n",
        "\n",
        "BQ_TABLE_VEGETATION = config['gridveg_point_intercepts']['bigquery']['table_vegetation']\n",
        "BQ_TABLE_GROUND = config['gridveg_point_intercepts']['bigquery']['table_ground']\n",
        "BQ_PROJECT = config['gridveg_point_intercepts']['bigquery'].get('project')\n",
        "\n",
        "# Verify required config values\n",
        "if not GCS_CSV_URL or GCS_CSV_URL.startswith('gs://your-'):\n",
        "    raise ValueError(\"Please configure gridveg_point_intercepts.gcs.csv_url in config.yml\")\n",
        "if not BQ_TABLE_VEGETATION or 'your-project' in BQ_TABLE_VEGETATION:\n",
        "    raise ValueError(\"Please configure gridveg_point_intercepts.bigquery.table_vegetation in config.yml\")\n",
        "if not BQ_TABLE_GROUND or 'your-project' in BQ_TABLE_GROUND:\n",
        "    raise ValueError(\"Please configure gridveg_point_intercepts.bigquery.table_ground in config.yml\")\n",
        "\n",
        "print(\"✓ Configuration loaded successfully\")\n",
        "print(f\"  CSV URL: {GCS_CSV_URL[:60]}...\" if len(GCS_CSV_URL) > 60 else f\"  CSV URL: {GCS_CSV_URL}\")\n",
        "print(f\"  Vegetation Table: {BQ_TABLE_VEGETATION}\")\n",
        "print(f\"  Ground Table: {BQ_TABLE_GROUND}\")\n",
        "print(f\"  Backup: gs://{BACKUP_BUCKET}/{BACKUP_PREFIX}\" if BACKUP_BUCKET else \"  Backup: Not configured\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Clients initialized\n",
            "  Project: mpg-data-warehouse\n"
          ]
        }
      ],
      "source": [
        "# Initialize clients\n",
        "bq_client = bigquery.Client(project=BQ_PROJECT) if BQ_PROJECT else bigquery.Client()\n",
        "storage_client = storage.Client(project=BQ_PROJECT) if BQ_PROJECT else storage.Client()\n",
        "\n",
        "print(f\"✓ Clients initialized\")\n",
        "print(f\"  Project: {bq_client.project}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading CSV from GCS...\n",
            "✓ CSV loaded successfully:\n",
            "  Rows: 7799\n",
            "  Columns: ['Survey Data::__kp_Survey', 'Survey Data::_kf_Site', 'Survey Data::SurveyDate', 'Survey Data::SurveyYear', 'PointTrans', '_kf_Hit1_serial', 'Height', '_kf_Hit2_serial', '_kf_Hit3_serial', '_kf_Hit4_serial', 'GroundCover']\n",
            "\n",
            "First few rows:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survey Data::__kp_Survey</th>\n",
              "      <th>Survey Data::_kf_Site</th>\n",
              "      <th>Survey Data::SurveyDate</th>\n",
              "      <th>Survey Data::SurveyYear</th>\n",
              "      <th>PointTrans</th>\n",
              "      <th>_kf_Hit1_serial</th>\n",
              "      <th>Height</th>\n",
              "      <th>_kf_Hit2_serial</th>\n",
              "      <th>_kf_Hit3_serial</th>\n",
              "      <th>_kf_Hit4_serial</th>\n",
              "      <th>GroundCover</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B45700C5-D391-4679-8579-217DCB1385A2</td>\n",
              "      <td>227</td>\n",
              "      <td>5/21/25</td>\n",
              "      <td>2025</td>\n",
              "      <td>N1</td>\n",
              "      <td>529</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B45700C5-D391-4679-8579-217DCB1385A2</td>\n",
              "      <td>227</td>\n",
              "      <td>5/21/25</td>\n",
              "      <td>2025</td>\n",
              "      <td>N2</td>\n",
              "      <td>360</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B45700C5-D391-4679-8579-217DCB1385A2</td>\n",
              "      <td>227</td>\n",
              "      <td>5/21/25</td>\n",
              "      <td>2025</td>\n",
              "      <td>N3</td>\n",
              "      <td>529</td>\n",
              "      <td>NaN</td>\n",
              "      <td>405.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B45700C5-D391-4679-8579-217DCB1385A2</td>\n",
              "      <td>227</td>\n",
              "      <td>5/21/25</td>\n",
              "      <td>2025</td>\n",
              "      <td>N4</td>\n",
              "      <td>529</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>WDL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B45700C5-D391-4679-8579-217DCB1385A2</td>\n",
              "      <td>227</td>\n",
              "      <td>5/21/25</td>\n",
              "      <td>2025</td>\n",
              "      <td>N5</td>\n",
              "      <td>334</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>WDL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Survey Data::__kp_Survey  Survey Data::_kf_Site  \\\n",
              "0  B45700C5-D391-4679-8579-217DCB1385A2                    227   \n",
              "1  B45700C5-D391-4679-8579-217DCB1385A2                    227   \n",
              "2  B45700C5-D391-4679-8579-217DCB1385A2                    227   \n",
              "3  B45700C5-D391-4679-8579-217DCB1385A2                    227   \n",
              "4  B45700C5-D391-4679-8579-217DCB1385A2                    227   \n",
              "\n",
              "  Survey Data::SurveyDate  Survey Data::SurveyYear PointTrans  \\\n",
              "0                 5/21/25                     2025         N1   \n",
              "1                 5/21/25                     2025         N2   \n",
              "2                 5/21/25                     2025         N3   \n",
              "3                 5/21/25                     2025         N4   \n",
              "4                 5/21/25                     2025         N5   \n",
              "\n",
              "   _kf_Hit1_serial  Height  _kf_Hit2_serial  _kf_Hit3_serial  _kf_Hit4_serial  \\\n",
              "0              529     NaN              NaN              NaN              NaN   \n",
              "1              360     NaN              NaN              NaN              NaN   \n",
              "2              529     NaN            405.0              NaN              NaN   \n",
              "3              529     NaN              NaN              NaN              NaN   \n",
              "4              334     NaN              NaN              NaN              NaN   \n",
              "\n",
              "  GroundCover  \n",
              "0           L  \n",
              "1           L  \n",
              "2           L  \n",
              "3         WDL  \n",
              "4         WDL  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Read CSV from GCS (new data)\n",
        "print(\"Reading CSV from GCS...\")\n",
        "df_new = pd.read_csv(GCS_CSV_URL)\n",
        "\n",
        "print(f\"✓ CSV loaded successfully:\")\n",
        "print(f\"  Rows: {len(df_new)}\")\n",
        "print(f\"  Columns: {list(df_new.columns)}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "df_new.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transform CSV Data\n",
        "\n",
        "The source CSV will be transformed into two separate datasets:\n",
        "\n",
        "### Vegetation Table Transformations\n",
        "- Rename columns to match BigQuery schema\n",
        "- Convert date format from mm/dd/yy to ISO format (YYYY-MM-DD)\n",
        "- Filter out 2010 records (per requirements)\n",
        "- Select columns: survey_ID, grid_point, date, year, transect_point, height_intercept_1, intercept_1-4\n",
        "\n",
        "### Ground Table Transformations\n",
        "- Rename columns to match BigQuery schema  \n",
        "- Convert date format from mm/dd/yy to ISO format (YYYY-MM-DD)\n",
        "- Filter out 2010 records (per requirements)\n",
        "- Select columns: survey_ID, grid_point, date, year, transect_point, intercept_1, intercept_ground_code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vegetation table column mapping:\n",
            "  Survey Data::__kp_Survey       → survey_ID\n",
            "  Survey Data::_kf_Site          → grid_point\n",
            "  Survey Data::SurveyDate        → date\n",
            "  Survey Data::SurveyYear        → year\n",
            "  PointTrans                     → transect_point\n",
            "  Height                         → height_intercept_1\n",
            "  _kf_Hit1_serial                → intercept_1\n",
            "  _kf_Hit2_serial                → intercept_2\n",
            "  _kf_Hit3_serial                → intercept_3\n",
            "  _kf_Hit4_serial                → intercept_4\n"
          ]
        }
      ],
      "source": [
        "# Define column mapping for VEGETATION table\n",
        "column_mapping_vegetation = {\n",
        "    'Survey Data::__kp_Survey': 'survey_ID',\n",
        "    'Survey Data::_kf_Site': 'grid_point',\n",
        "    'Survey Data::SurveyDate': 'date',\n",
        "    'Survey Data::SurveyYear': 'year',\n",
        "    'PointTrans': 'transect_point',\n",
        "    'Height': 'height_intercept_1',\n",
        "    '_kf_Hit1_serial': 'intercept_1',\n",
        "    '_kf_Hit2_serial': 'intercept_2',\n",
        "    '_kf_Hit3_serial': 'intercept_3',\n",
        "    '_kf_Hit4_serial': 'intercept_4'\n",
        "}\n",
        "\n",
        "print(\"Vegetation table column mapping:\")\n",
        "for csv_col, bq_col in column_mapping_vegetation.items():\n",
        "    print(f\"  {csv_col:30s} → {bq_col}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ground table column mapping:\n",
            "  Survey Data::__kp_Survey       → survey_ID\n",
            "  Survey Data::_kf_Site          → grid_point\n",
            "  Survey Data::SurveyDate        → date\n",
            "  Survey Data::SurveyYear        → year\n",
            "  PointTrans                     → transect_point\n",
            "  _kf_Hit1_serial                → intercept_1\n",
            "  GroundCover                    → intercept_ground_code\n"
          ]
        }
      ],
      "source": [
        "# Define column mapping for GROUND table\n",
        "column_mapping_ground = {\n",
        "    'Survey Data::__kp_Survey': 'survey_ID',\n",
        "    'Survey Data::_kf_Site': 'grid_point',\n",
        "    'Survey Data::SurveyDate': 'date',\n",
        "    'Survey Data::SurveyYear': 'year',\n",
        "    'PointTrans': 'transect_point',\n",
        "    '_kf_Hit1_serial': 'intercept_1',\n",
        "    'GroundCover': 'intercept_ground_code'\n",
        "}\n",
        "\n",
        "print(\"Ground table column mapping:\")\n",
        "for csv_col, bq_col in column_mapping_ground.items():\n",
        "    print(f\"  {csv_col:30s} → {bq_col}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "TRANSFORMING DATA FOR VEGETATION TABLE\n",
            "============================================================\n",
            "\n",
            "✓ Columns renamed\n",
            "  Transformed columns: ['survey_ID', 'grid_point', 'date', 'year', 'transect_point', 'height_intercept_1', 'intercept_1', 'intercept_2', 'intercept_3', 'intercept_4']\n",
            "✓ Date format converted to date type\n",
            "  Sample dates: [datetime.date(2025, 5, 21), datetime.date(2025, 5, 21), datetime.date(2025, 5, 21)]\n",
            "\n",
            "✓ Filtered out 2010 records\n",
            "  Rows before: 7799\n",
            "  Rows after:  7799\n",
            "  Removed:     0\n",
            "\n",
            "Vegetation data preview:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survey_ID</th>\n",
              "      <th>grid_point</th>\n",
              "      <th>date</th>\n",
              "      <th>year</th>\n",
              "      <th>transect_point</th>\n",
              "      <th>height_intercept_1</th>\n",
              "      <th>intercept_1</th>\n",
              "      <th>intercept_2</th>\n",
              "      <th>intercept_3</th>\n",
              "      <th>intercept_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B45700C5-D391-4679-8579-217DCB1385A2</td>\n",
              "      <td>227</td>\n",
              "      <td>2025-05-21</td>\n",
              "      <td>2025</td>\n",
              "      <td>N1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>529</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B45700C5-D391-4679-8579-217DCB1385A2</td>\n",
              "      <td>227</td>\n",
              "      <td>2025-05-21</td>\n",
              "      <td>2025</td>\n",
              "      <td>N2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>360</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B45700C5-D391-4679-8579-217DCB1385A2</td>\n",
              "      <td>227</td>\n",
              "      <td>2025-05-21</td>\n",
              "      <td>2025</td>\n",
              "      <td>N3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>529</td>\n",
              "      <td>405.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B45700C5-D391-4679-8579-217DCB1385A2</td>\n",
              "      <td>227</td>\n",
              "      <td>2025-05-21</td>\n",
              "      <td>2025</td>\n",
              "      <td>N4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>529</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B45700C5-D391-4679-8579-217DCB1385A2</td>\n",
              "      <td>227</td>\n",
              "      <td>2025-05-21</td>\n",
              "      <td>2025</td>\n",
              "      <td>N5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>334</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              survey_ID  grid_point        date  year  \\\n",
              "0  B45700C5-D391-4679-8579-217DCB1385A2         227  2025-05-21  2025   \n",
              "1  B45700C5-D391-4679-8579-217DCB1385A2         227  2025-05-21  2025   \n",
              "2  B45700C5-D391-4679-8579-217DCB1385A2         227  2025-05-21  2025   \n",
              "3  B45700C5-D391-4679-8579-217DCB1385A2         227  2025-05-21  2025   \n",
              "4  B45700C5-D391-4679-8579-217DCB1385A2         227  2025-05-21  2025   \n",
              "\n",
              "  transect_point  height_intercept_1  intercept_1  intercept_2  intercept_3  \\\n",
              "0             N1                 NaN          529          NaN          NaN   \n",
              "1             N2                 NaN          360          NaN          NaN   \n",
              "2             N3                 NaN          529        405.0          NaN   \n",
              "3             N4                 NaN          529          NaN          NaN   \n",
              "4             N5                 NaN          334          NaN          NaN   \n",
              "\n",
              "   intercept_4  \n",
              "0          NaN  \n",
              "1          NaN  \n",
              "2          NaN  \n",
              "3          NaN  \n",
              "4          NaN  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Transform data for VEGETATION table\n",
        "print(\"=\" * 60)\n",
        "print(\"TRANSFORMING DATA FOR VEGETATION TABLE\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Select and rename columns\n",
        "df_vegetation = df_new[list(column_mapping_vegetation.keys())].copy()\n",
        "df_vegetation = df_vegetation.rename(columns=column_mapping_vegetation)\n",
        "\n",
        "print(f\"\\n✓ Columns renamed\")\n",
        "print(f\"  Transformed columns: {list(df_vegetation.columns)}\")\n",
        "\n",
        "# Convert date from m/d/yy to proper datetime/date format\n",
        "df_vegetation['date'] = pd.to_datetime(df_vegetation['date'], format='%m/%d/%y').dt.date\n",
        "\n",
        "print(f\"✓ Date format converted to date type\")\n",
        "print(f\"  Sample dates: {df_vegetation['date'].head(3).tolist()}\")\n",
        "\n",
        "# Filter out 2010 records\n",
        "rows_before = len(df_vegetation)\n",
        "df_vegetation = df_vegetation[df_vegetation['year'] != 2010].copy()\n",
        "rows_after = len(df_vegetation)\n",
        "\n",
        "print(f\"\\n✓ Filtered out 2010 records\")\n",
        "print(f\"  Rows before: {rows_before}\")\n",
        "print(f\"  Rows after:  {rows_after}\")\n",
        "print(f\"  Removed:     {rows_before - rows_after}\")\n",
        "\n",
        "print(f\"\\nVegetation data preview:\")\n",
        "df_vegetation.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "TRANSFORMING DATA FOR GROUND TABLE\n",
            "============================================================\n",
            "\n",
            "✓ Columns renamed\n",
            "  Transformed columns: ['survey_ID', 'grid_point', 'date', 'year', 'transect_point', 'intercept_1', 'intercept_ground_code']\n",
            "✓ Date format converted to date type\n",
            "  Sample dates: [datetime.date(2025, 5, 21), datetime.date(2025, 5, 21), datetime.date(2025, 5, 21)]\n",
            "\n",
            "✓ Filtered out 2010 records\n",
            "  Rows before: 7799\n",
            "  Rows after:  7799\n",
            "  Removed:     0\n",
            "\n",
            "Ground data preview:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survey_ID</th>\n",
              "      <th>grid_point</th>\n",
              "      <th>date</th>\n",
              "      <th>year</th>\n",
              "      <th>transect_point</th>\n",
              "      <th>intercept_1</th>\n",
              "      <th>intercept_ground_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B45700C5-D391-4679-8579-217DCB1385A2</td>\n",
              "      <td>227</td>\n",
              "      <td>2025-05-21</td>\n",
              "      <td>2025</td>\n",
              "      <td>N1</td>\n",
              "      <td>529</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B45700C5-D391-4679-8579-217DCB1385A2</td>\n",
              "      <td>227</td>\n",
              "      <td>2025-05-21</td>\n",
              "      <td>2025</td>\n",
              "      <td>N2</td>\n",
              "      <td>360</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B45700C5-D391-4679-8579-217DCB1385A2</td>\n",
              "      <td>227</td>\n",
              "      <td>2025-05-21</td>\n",
              "      <td>2025</td>\n",
              "      <td>N3</td>\n",
              "      <td>529</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B45700C5-D391-4679-8579-217DCB1385A2</td>\n",
              "      <td>227</td>\n",
              "      <td>2025-05-21</td>\n",
              "      <td>2025</td>\n",
              "      <td>N4</td>\n",
              "      <td>529</td>\n",
              "      <td>WDL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B45700C5-D391-4679-8579-217DCB1385A2</td>\n",
              "      <td>227</td>\n",
              "      <td>2025-05-21</td>\n",
              "      <td>2025</td>\n",
              "      <td>N5</td>\n",
              "      <td>334</td>\n",
              "      <td>WDL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              survey_ID  grid_point        date  year  \\\n",
              "0  B45700C5-D391-4679-8579-217DCB1385A2         227  2025-05-21  2025   \n",
              "1  B45700C5-D391-4679-8579-217DCB1385A2         227  2025-05-21  2025   \n",
              "2  B45700C5-D391-4679-8579-217DCB1385A2         227  2025-05-21  2025   \n",
              "3  B45700C5-D391-4679-8579-217DCB1385A2         227  2025-05-21  2025   \n",
              "4  B45700C5-D391-4679-8579-217DCB1385A2         227  2025-05-21  2025   \n",
              "\n",
              "  transect_point  intercept_1 intercept_ground_code  \n",
              "0             N1          529                     L  \n",
              "1             N2          360                     L  \n",
              "2             N3          529                     L  \n",
              "3             N4          529                   WDL  \n",
              "4             N5          334                   WDL  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Transform data for GROUND table\n",
        "print(\"=\" * 60)\n",
        "print(\"TRANSFORMING DATA FOR GROUND TABLE\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Select and rename columns\n",
        "df_ground = df_new[list(column_mapping_ground.keys())].copy()\n",
        "df_ground = df_ground.rename(columns=column_mapping_ground)\n",
        "\n",
        "print(f\"\\n✓ Columns renamed\")\n",
        "print(f\"  Transformed columns: {list(df_ground.columns)}\")\n",
        "\n",
        "# Convert date from m/d/yy to proper datetime/date format\n",
        "df_ground['date'] = pd.to_datetime(df_ground['date'], format='%m/%d/%y').dt.date\n",
        "\n",
        "print(f\"✓ Date format converted to date type\")\n",
        "print(f\"  Sample dates: {df_ground['date'].head(3).tolist()}\")\n",
        "\n",
        "# Filter out 2010 records\n",
        "rows_before = len(df_ground)\n",
        "df_ground = df_ground[df_ground['year'] != 2010].copy()\n",
        "rows_after = len(df_ground)\n",
        "\n",
        "print(f\"\\n✓ Filtered out 2010 records\")\n",
        "print(f\"  Rows before: {rows_before}\")\n",
        "print(f\"  Rows after:  {rows_after}\")\n",
        "print(f\"  Removed:     {rows_before - rows_after}\")\n",
        "\n",
        "print(f\"\\nGround data preview:\")\n",
        "df_ground.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Read Existing BigQuery Tables\n",
        "\n",
        "Load the current data from both BigQuery tables to compare with the new data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading existing VEGETATION data from mpg-data-warehouse.vegetation_point_intercept_gridVeg.gridVeg_point_intercept_vegetation...\n",
            "✓ Existing vegetation table loaded:\n",
            "  Rows: 291045\n",
            "  Columns: ['survey_ID', 'grid_point', 'date', 'year', 'transect_point', 'height_intercept_1', 'intercept_1', 'intercept_2', 'intercept_3', 'intercept_4']\n",
            "\n",
            "Existing vegetation data preview:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survey_ID</th>\n",
              "      <th>grid_point</th>\n",
              "      <th>date</th>\n",
              "      <th>year</th>\n",
              "      <th>transect_point</th>\n",
              "      <th>height_intercept_1</th>\n",
              "      <th>intercept_1</th>\n",
              "      <th>intercept_2</th>\n",
              "      <th>intercept_3</th>\n",
              "      <th>intercept_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>01E14610-A291-4929-98A9-687132272D70</td>\n",
              "      <td>306</td>\n",
              "      <td>2023-05-24</td>\n",
              "      <td>2023</td>\n",
              "      <td>N3</td>\n",
              "      <td>None</td>\n",
              "      <td>525</td>\n",
              "      <td>12</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>01E14610-A291-4929-98A9-687132272D70</td>\n",
              "      <td>306</td>\n",
              "      <td>2023-05-24</td>\n",
              "      <td>2023</td>\n",
              "      <td>N23</td>\n",
              "      <td>None</td>\n",
              "      <td>525</td>\n",
              "      <td>5</td>\n",
              "      <td>529</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>01E14610-A291-4929-98A9-687132272D70</td>\n",
              "      <td>306</td>\n",
              "      <td>2023-05-24</td>\n",
              "      <td>2023</td>\n",
              "      <td>N30</td>\n",
              "      <td>None</td>\n",
              "      <td>525</td>\n",
              "      <td>5</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>01E14610-A291-4929-98A9-687132272D70</td>\n",
              "      <td>306</td>\n",
              "      <td>2023-05-24</td>\n",
              "      <td>2023</td>\n",
              "      <td>E5</td>\n",
              "      <td>None</td>\n",
              "      <td>525</td>\n",
              "      <td>67</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>01E14610-A291-4929-98A9-687132272D70</td>\n",
              "      <td>306</td>\n",
              "      <td>2023-05-24</td>\n",
              "      <td>2023</td>\n",
              "      <td>E17</td>\n",
              "      <td>None</td>\n",
              "      <td>525</td>\n",
              "      <td>12</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              survey_ID  grid_point        date  year  \\\n",
              "0  01E14610-A291-4929-98A9-687132272D70         306  2023-05-24  2023   \n",
              "1  01E14610-A291-4929-98A9-687132272D70         306  2023-05-24  2023   \n",
              "2  01E14610-A291-4929-98A9-687132272D70         306  2023-05-24  2023   \n",
              "3  01E14610-A291-4929-98A9-687132272D70         306  2023-05-24  2023   \n",
              "4  01E14610-A291-4929-98A9-687132272D70         306  2023-05-24  2023   \n",
              "\n",
              "  transect_point height_intercept_1  intercept_1  intercept_2  intercept_3  \\\n",
              "0             N3               None          525           12         <NA>   \n",
              "1            N23               None          525            5          529   \n",
              "2            N30               None          525            5         <NA>   \n",
              "3             E5               None          525           67         <NA>   \n",
              "4            E17               None          525           12         <NA>   \n",
              "\n",
              "   intercept_4  \n",
              "0         <NA>  \n",
              "1         <NA>  \n",
              "2         <NA>  \n",
              "3         <NA>  \n",
              "4         <NA>  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Read existing VEGETATION table from BigQuery\n",
        "print(f\"Reading existing VEGETATION data from {BQ_TABLE_VEGETATION}...\")\n",
        "query = f\"SELECT * FROM `{BQ_TABLE_VEGETATION}`\"\n",
        "\n",
        "try:\n",
        "    df_existing_vegetation = bq_client.query(query).to_dataframe()\n",
        "    print(f\"✓ Existing vegetation table loaded:\")\n",
        "    print(f\"  Rows: {len(df_existing_vegetation)}\")\n",
        "    print(f\"  Columns: {list(df_existing_vegetation.columns)}\")\n",
        "    print(f\"\\nExisting vegetation data preview:\")\n",
        "    display(df_existing_vegetation.head())\n",
        "except Exception as e:\n",
        "    print(f\"⚠ Error reading table: {e}\")\n",
        "    print(\"  This may be expected if the table doesn't exist yet.\")\n",
        "    df_existing_vegetation = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading existing GROUND data from mpg-data-warehouse.vegetation_point_intercept_gridVeg.gridVeg_point_intercept_ground...\n",
            "✓ Existing ground table loaded:\n",
            "  Rows: 291045\n",
            "  Columns: ['survey_ID', 'grid_point', 'date', 'year', 'transect_point', 'intercept_1', 'intercept_ground_code']\n",
            "\n",
            "Existing ground data preview:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survey_ID</th>\n",
              "      <th>grid_point</th>\n",
              "      <th>date</th>\n",
              "      <th>year</th>\n",
              "      <th>transect_point</th>\n",
              "      <th>intercept_1</th>\n",
              "      <th>intercept_ground_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0B3C78C3-5612-4BC3-A14F-B4D7A7041C35</td>\n",
              "      <td>586</td>\n",
              "      <td>2022-05-16</td>\n",
              "      <td>2022</td>\n",
              "      <td>E29</td>\n",
              "      <td>360</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0B3C78C3-5612-4BC3-A14F-B4D7A7041C35</td>\n",
              "      <td>586</td>\n",
              "      <td>2022-05-16</td>\n",
              "      <td>2022</td>\n",
              "      <td>E41</td>\n",
              "      <td>360</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0B3C78C3-5612-4BC3-A14F-B4D7A7041C35</td>\n",
              "      <td>586</td>\n",
              "      <td>2022-05-16</td>\n",
              "      <td>2022</td>\n",
              "      <td>E43</td>\n",
              "      <td>360</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0B3C78C3-5612-4BC3-A14F-B4D7A7041C35</td>\n",
              "      <td>586</td>\n",
              "      <td>2022-05-16</td>\n",
              "      <td>2022</td>\n",
              "      <td>E46</td>\n",
              "      <td>360</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0B3C78C3-5612-4BC3-A14F-B4D7A7041C35</td>\n",
              "      <td>586</td>\n",
              "      <td>2022-05-16</td>\n",
              "      <td>2022</td>\n",
              "      <td>E44</td>\n",
              "      <td>360</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              survey_ID  grid_point        date  year  \\\n",
              "0  0B3C78C3-5612-4BC3-A14F-B4D7A7041C35         586  2022-05-16  2022   \n",
              "1  0B3C78C3-5612-4BC3-A14F-B4D7A7041C35         586  2022-05-16  2022   \n",
              "2  0B3C78C3-5612-4BC3-A14F-B4D7A7041C35         586  2022-05-16  2022   \n",
              "3  0B3C78C3-5612-4BC3-A14F-B4D7A7041C35         586  2022-05-16  2022   \n",
              "4  0B3C78C3-5612-4BC3-A14F-B4D7A7041C35         586  2022-05-16  2022   \n",
              "\n",
              "  transect_point  intercept_1 intercept_ground_code  \n",
              "0            E29          360                  None  \n",
              "1            E41          360                  None  \n",
              "2            E43          360                  None  \n",
              "3            E46          360                  None  \n",
              "4            E44          360                  None  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Read existing GROUND table from BigQuery\n",
        "print(f\"Reading existing GROUND data from {BQ_TABLE_GROUND}...\")\n",
        "query = f\"SELECT * FROM `{BQ_TABLE_GROUND}`\"\n",
        "\n",
        "try:\n",
        "    df_existing_ground = bq_client.query(query).to_dataframe()\n",
        "    print(f\"✓ Existing ground table loaded:\")\n",
        "    print(f\"  Rows: {len(df_existing_ground)}\")\n",
        "    print(f\"  Columns: {list(df_existing_ground.columns)}\")\n",
        "    print(f\"\\nExisting ground data preview:\")\n",
        "    display(df_existing_ground.head())\n",
        "except Exception as e:\n",
        "    print(f\"⚠ Error reading table: {e}\")\n",
        "    print(\"  This may be expected if the table doesn't exist yet.\")\n",
        "    df_existing_ground = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compare New vs Existing Data\n",
        "\n",
        "Identify which rows in the new data are not already in the existing tables.\n",
        "\n",
        "**Unique identifier**: `survey_ID + transect_point` (each survey has multiple transect points)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "COMPARING VEGETATION DATA\n",
            "============================================================\n",
            "\n",
            "Row count:\n",
            "  Existing: 291045\n",
            "  New CSV:  7799\n",
            "\n",
            "✓ Columns match (10 columns)\n",
            "\n",
            "✓ Found 7799 new vegetation records to append\n",
            "\n",
            "New records by year:\n",
            "  2025: 7799 records\n"
          ]
        }
      ],
      "source": [
        "# Compare VEGETATION datasets\n",
        "print(\"=\" * 60)\n",
        "print(\"COMPARING VEGETATION DATA\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if df_existing_vegetation is not None:\n",
        "    print(f\"\\nRow count:\")\n",
        "    print(f\"  Existing: {len(df_existing_vegetation)}\")\n",
        "    print(f\"  New CSV:  {len(df_vegetation)}\")\n",
        "    \n",
        "    # Column comparison\n",
        "    existing_cols = set(df_existing_vegetation.columns)\n",
        "    new_cols = set(df_vegetation.columns)\n",
        "    \n",
        "    if existing_cols == new_cols:\n",
        "        print(f\"\\n✓ Columns match ({len(new_cols)} columns)\")\n",
        "    else:\n",
        "        print(\"\\n⚠ Column differences detected:\")\n",
        "        if new_cols - existing_cols:\n",
        "            print(f\"  New columns: {new_cols - existing_cols}\")\n",
        "        if existing_cols - new_cols:\n",
        "            print(f\"  Missing columns: {existing_cols - new_cols}\")\n",
        "    \n",
        "    # Create composite key for comparison\n",
        "    df_existing_vegetation['_composite_key'] = (\n",
        "        df_existing_vegetation['survey_ID'].astype(str) + '|' + \n",
        "        df_existing_vegetation['transect_point'].astype(str)\n",
        "    )\n",
        "    df_vegetation['_composite_key'] = (\n",
        "        df_vegetation['survey_ID'].astype(str) + '|' + \n",
        "        df_vegetation['transect_point'].astype(str)\n",
        "    )\n",
        "    \n",
        "    existing_keys = set(df_existing_vegetation['_composite_key'])\n",
        "    new_keys = set(df_vegetation['_composite_key'])\n",
        "    \n",
        "    # Find records to append\n",
        "    keys_to_append = new_keys - existing_keys\n",
        "    \n",
        "    if keys_to_append:\n",
        "        df_vegetation_to_append = df_vegetation[df_vegetation['_composite_key'].isin(keys_to_append)].copy()\n",
        "        # Drop the temporary composite key\n",
        "        df_vegetation_to_append = df_vegetation_to_append.drop(columns=['_composite_key'])\n",
        "        \n",
        "        print(f\"\\n✓ Found {len(df_vegetation_to_append)} new vegetation records to append\")\n",
        "        \n",
        "        # Show year breakdown\n",
        "        print(f\"\\nNew records by year:\")\n",
        "        year_counts = df_vegetation_to_append['year'].value_counts().sort_index()\n",
        "        for year, count in year_counts.items():\n",
        "            print(f\"  {year}: {count} records\")\n",
        "    else:\n",
        "        df_vegetation_to_append = None\n",
        "        print(\"\\n⚠ No new records found - all keys already exist in table\")\n",
        "    \n",
        "    # Check for duplicates\n",
        "    duplicate_keys = existing_keys & new_keys\n",
        "    if duplicate_keys:\n",
        "        print(f\"\\n⚠ Warning: {len(duplicate_keys)} records already exist in table\")\n",
        "        print(f\"  These will be skipped during append.\")\n",
        "else:\n",
        "    # No existing table, all records are new\n",
        "    df_vegetation_to_append = df_vegetation.copy()\n",
        "    print(f\"✓ No existing table - will create new table with {len(df_vegetation_to_append)} records\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "COMPARING GROUND DATA\n",
            "============================================================\n",
            "\n",
            "Row count:\n",
            "  Existing: 291045\n",
            "  New CSV:  7799\n",
            "\n",
            "✓ Columns match (7 columns)\n",
            "\n",
            "✓ Found 7799 new ground records to append\n",
            "\n",
            "New records by year:\n",
            "  2025: 7799 records\n"
          ]
        }
      ],
      "source": [
        "# Compare GROUND datasets\n",
        "print(\"=\" * 60)\n",
        "print(\"COMPARING GROUND DATA\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if df_existing_ground is not None:\n",
        "    print(f\"\\nRow count:\")\n",
        "    print(f\"  Existing: {len(df_existing_ground)}\")\n",
        "    print(f\"  New CSV:  {len(df_ground)}\")\n",
        "    \n",
        "    # Column comparison\n",
        "    existing_cols = set(df_existing_ground.columns)\n",
        "    new_cols = set(df_ground.columns)\n",
        "    \n",
        "    if existing_cols == new_cols:\n",
        "        print(f\"\\n✓ Columns match ({len(new_cols)} columns)\")\n",
        "    else:\n",
        "        print(\"\\n⚠ Column differences detected:\")\n",
        "        if new_cols - existing_cols:\n",
        "            print(f\"  New columns: {new_cols - existing_cols}\")\n",
        "        if existing_cols - new_cols:\n",
        "            print(f\"  Missing columns: {existing_cols - new_cols}\")\n",
        "    \n",
        "    # Create composite key for comparison\n",
        "    df_existing_ground['_composite_key'] = (\n",
        "        df_existing_ground['survey_ID'].astype(str) + '|' + \n",
        "        df_existing_ground['transect_point'].astype(str)\n",
        "    )\n",
        "    df_ground['_composite_key'] = (\n",
        "        df_ground['survey_ID'].astype(str) + '|' + \n",
        "        df_ground['transect_point'].astype(str)\n",
        "    )\n",
        "    \n",
        "    existing_keys = set(df_existing_ground['_composite_key'])\n",
        "    new_keys = set(df_ground['_composite_key'])\n",
        "    \n",
        "    # Find records to append\n",
        "    keys_to_append = new_keys - existing_keys\n",
        "    \n",
        "    if keys_to_append:\n",
        "        df_ground_to_append = df_ground[df_ground['_composite_key'].isin(keys_to_append)].copy()\n",
        "        # Drop the temporary composite key\n",
        "        df_ground_to_append = df_ground_to_append.drop(columns=['_composite_key'])\n",
        "        \n",
        "        print(f\"\\n✓ Found {len(df_ground_to_append)} new ground records to append\")\n",
        "        \n",
        "        # Show year breakdown\n",
        "        print(f\"\\nNew records by year:\")\n",
        "        year_counts = df_ground_to_append['year'].value_counts().sort_index()\n",
        "        for year, count in year_counts.items():\n",
        "            print(f\"  {year}: {count} records\")\n",
        "    else:\n",
        "        df_ground_to_append = None\n",
        "        print(\"\\n⚠ No new records found - all keys already exist in table\")\n",
        "    \n",
        "    # Check for duplicates\n",
        "    duplicate_keys = existing_keys & new_keys\n",
        "    if duplicate_keys:\n",
        "        print(f\"\\n⚠ Warning: {len(duplicate_keys)} records already exist in table\")\n",
        "        print(f\"  These will be skipped during append.\")\n",
        "else:\n",
        "    # No existing table, all records are new\n",
        "    df_ground_to_append = df_ground.copy()\n",
        "    print(f\"✓ No existing table - will create new table with {len(df_ground_to_append)} records\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Diagnose Data Type Issues\n",
        "\n",
        "Before attempting upload, let's understand the data types and potential issues.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "VEGETATION DATA TYPES\n",
            "============================================================\n",
            "survey_ID              object\n",
            "grid_point              int64\n",
            "date                   object\n",
            "year                    int64\n",
            "transect_point         object\n",
            "height_intercept_1    float64\n",
            "intercept_1             int64\n",
            "intercept_2           float64\n",
            "intercept_3           float64\n",
            "intercept_4           float64\n",
            "_composite_key         object\n",
            "dtype: object\n",
            "\n",
            "Sample date value: 2025-05-21\n",
            "Date value type: <class 'datetime.date'>\n",
            "\n",
            "============================================================\n",
            "GROUND DATA TYPES\n",
            "============================================================\n",
            "survey_ID                object\n",
            "grid_point                int64\n",
            "date                     object\n",
            "year                      int64\n",
            "transect_point           object\n",
            "intercept_1               int64\n",
            "intercept_ground_code    object\n",
            "_composite_key           object\n",
            "dtype: object\n",
            "\n",
            "============================================================\n",
            "BIGQUERY SCHEMA EXPECTATIONS\n",
            "============================================================\n",
            "\n",
            "VEGETATION table schema:\n",
            "  survey_ID                : STRING     (mode: NULLABLE)\n",
            "  grid_point               : INTEGER    (mode: NULLABLE)\n",
            "  date                     : DATE       (mode: NULLABLE)\n",
            "  year                     : INTEGER    (mode: NULLABLE)\n",
            "  transect_point           : STRING     (mode: NULLABLE)\n",
            "  height_intercept_1       : NUMERIC    (mode: NULLABLE)\n",
            "  intercept_1              : INTEGER    (mode: NULLABLE)\n",
            "  intercept_2              : INTEGER    (mode: NULLABLE)\n",
            "  intercept_3              : INTEGER    (mode: NULLABLE)\n",
            "  intercept_4              : INTEGER    (mode: NULLABLE)\n",
            "\n",
            "GROUND table schema:\n",
            "  survey_ID                : STRING     (mode: NULLABLE)\n",
            "  grid_point               : INTEGER    (mode: NULLABLE)\n",
            "  date                     : DATE       (mode: NULLABLE)\n",
            "  year                     : INTEGER    (mode: NULLABLE)\n",
            "  transect_point           : STRING     (mode: NULLABLE)\n",
            "  intercept_1              : INTEGER    (mode: NULLABLE)\n",
            "  intercept_ground_code    : STRING     (mode: NULLABLE)\n"
          ]
        }
      ],
      "source": [
        "# Check current data types in transformed dataframes\n",
        "print(\"=\" * 60)\n",
        "print(\"VEGETATION DATA TYPES\")\n",
        "print(\"=\" * 60)\n",
        "print(df_vegetation.dtypes)\n",
        "print(f\"\\nSample date value: {df_vegetation['date'].iloc[0]}\")\n",
        "print(f\"Date value type: {type(df_vegetation['date'].iloc[0])}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"GROUND DATA TYPES\")\n",
        "print(\"=\" * 60)\n",
        "print(df_ground.dtypes)\n",
        "\n",
        "# Check BigQuery schema expectations\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"BIGQUERY SCHEMA EXPECTATIONS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "table_veg = bq_client.get_table(BQ_TABLE_VEGETATION)\n",
        "print(\"\\nVEGETATION table schema:\")\n",
        "for field in table_veg.schema:\n",
        "    print(f\"  {field.name:25s}: {field.field_type:10s} (mode: {field.mode})\")\n",
        "\n",
        "table_ground = bq_client.get_table(BQ_TABLE_GROUND)\n",
        "print(\"\\nGROUND table schema:\")\n",
        "for field in table_ground.schema:\n",
        "    print(f\"  {field.name:25s}: {field.field_type:10s} (mode: {field.mode})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Understanding the PyArrow Error\n",
        "\n",
        "The `ArrowInvalid: Got bytestring of length 8 (expected 16)` error occurs because:\n",
        "\n",
        "1. **Python date objects are 8 bytes** (year, month, day encoded)\n",
        "2. **PyArrow expects different sizes** depending on the target type\n",
        "3. **The error message \"expected 16\"** suggests it's looking for a UUID/GUID (128 bits = 16 bytes)\n",
        "\n",
        "**Common Causes:**\n",
        "- **Date columns**: Python `date` objects → BigQuery `DATE` type (PyArrow struggles with this conversion)\n",
        "- **Nullable integers**: Pandas `Int64` (nullable) → BigQuery `INTEGER` (PyArrow can't serialize the nullable type properly)\n",
        "- **Mixed string/UUID columns**: If `survey_ID` contains both integers and UUIDs, type inference fails\n",
        "\n",
        "**Solutions:**\n",
        "1. **CSV Upload Method** (recommended): Upload as CSV, let BigQuery parse types\n",
        "2. **Change BigQuery Schema**: Use `TIMESTAMP` instead of `DATE`, `FLOAT64` instead of `INTEGER` for nullable columns\n",
        "3. **Fix Data Types**: Convert all columns to PyArrow-compatible types (strings, float64, regular int64)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
