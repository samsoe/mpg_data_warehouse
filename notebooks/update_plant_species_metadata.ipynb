{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Update Plant Species Metadata in BigQuery\n",
        "\n",
        "This notebook updates plant species metadata in BigQuery from a CSV file stored in GCS.\n",
        "\n",
        "## Requirements\n",
        "- Google Cloud credentials configured\n",
        "- Environment variables set (see `config.example.py`)\n",
        "- Required packages: google-cloud-bigquery, google-cloud-storage, pandas, python-dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "from google.cloud import bigquery\n",
        "from google.cloud import storage\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "print(\"Libraries imported successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load configuration from environment variables\n",
        "GCS_CSV_URL = os.getenv('PLANT_SPECIES_CSV_URL')\n",
        "BQ_TABLE_ID = os.getenv('PLANT_SPECIES_TABLE_ID')\n",
        "\n",
        "# Verify environment variables are set\n",
        "if not GCS_CSV_URL:\n",
        "    raise ValueError(\"PLANT_SPECIES_CSV_URL environment variable not set\")\n",
        "if not BQ_TABLE_ID:\n",
        "    raise ValueError(\"PLANT_SPECIES_TABLE_ID environment variable not set\")\n",
        "\n",
        "print(f\"Configuration loaded:\")\n",
        "print(f\"  CSV URL configured: {bool(GCS_CSV_URL)}\")\n",
        "print(f\"  Table ID configured: {bool(BQ_TABLE_ID)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize BigQuery client\n",
        "bq_client = bigquery.Client()\n",
        "print(f\"BigQuery client initialized for project: {bq_client.project}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read CSV from GCS\n",
        "# GCS_CSV_URL should be in format: gs://bucket-name/path/to/file.csv\n",
        "print(\"Reading CSV from GCS...\")\n",
        "df = pd.read_csv(GCS_CSV_URL)\n",
        "\n",
        "print(f\"CSV loaded successfully:\")\n",
        "print(f\"  Rows: {len(df)}\")\n",
        "print(f\"  Columns: {list(df.columns)}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display basic statistics about the data\n",
        "print(\"Data Info:\")\n",
        "df.info()\n",
        "print(\"\\nData Description:\")\n",
        "df.describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "In the next iteration, we'll add:\n",
        "1. Data validation and cleaning\n",
        "2. BigQuery table update logic\n",
        "3. Error handling and logging\n",
        "4. Dry-run mode to preview changes\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
