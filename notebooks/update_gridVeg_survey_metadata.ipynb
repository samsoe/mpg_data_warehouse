{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Update gridVeg Survey Metadata in BigQuery\n",
        "\n",
        "This notebook appends new survey metadata to the BigQuery table from a CSV file stored in GCS.\n",
        "\n",
        "**Operation**: APPEND new rows (not replace entire table)\n",
        "\n",
        "## Requirements\n",
        "- Google Cloud credentials configured\n",
        "- Configuration file: copy `config.example.yml` to `config.yml` and fill in your values\n",
        "- Required packages: google-cloud-bigquery, google-cloud-storage, pandas, pyyaml\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import yaml\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from google.cloud import bigquery\n",
        "from google.cloud import storage\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"Libraries imported successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load configuration from YAML file\n",
        "config_path = Path(\"../config.yml\")\n",
        "\n",
        "if not config_path.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"Configuration file not found: {config_path}\\n\"\n",
        "        \"Please copy config.example.yml to config.yml and fill in your values.\"\n",
        "    )\n",
        "\n",
        "with open(config_path, 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "# Extract configuration values for gridVeg survey metadata\n",
        "GCS_CSV_URL = config['gridveg_survey_metadata']['gcs']['csv_url']\n",
        "BACKUP_BUCKET = config['gridveg_survey_metadata']['gcs'].get('backup_bucket')\n",
        "BACKUP_PREFIX = config['gridveg_survey_metadata']['gcs'].get('backup_prefix', 'backups/gridveg_survey_metadata')\n",
        "BQ_TABLE_ID = config['gridveg_survey_metadata']['bigquery']['table_id']\n",
        "BQ_PROJECT = config['gridveg_survey_metadata']['bigquery'].get('project')\n",
        "\n",
        "# Verify required config values\n",
        "if not GCS_CSV_URL or GCS_CSV_URL.startswith('gs://your-'):\n",
        "    raise ValueError(\"Please configure gridveg_survey_metadata.gcs.csv_url in config.yml\")\n",
        "if not BQ_TABLE_ID or 'your-project' in BQ_TABLE_ID:\n",
        "    raise ValueError(\"Please configure gridveg_survey_metadata.bigquery.table_id in config.yml\")\n",
        "\n",
        "print(\"✓ Configuration loaded successfully\")\n",
        "print(f\"  CSV URL: {GCS_CSV_URL[:60]}...\" if len(GCS_CSV_URL) > 60 else f\"  CSV URL: {GCS_CSV_URL}\")\n",
        "print(f\"  Table ID: {BQ_TABLE_ID}\")\n",
        "print(f\"  Backup: gs://{BACKUP_BUCKET}/{BACKUP_PREFIX}\" if BACKUP_BUCKET else \"  Backup: Not configured\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Clients initialized\n",
            "  Project: mpg-data-warehouse\n"
          ]
        }
      ],
      "source": [
        "# Initialize clients\n",
        "bq_client = bigquery.Client(project=BQ_PROJECT) if BQ_PROJECT else bigquery.Client()\n",
        "storage_client = storage.Client(project=BQ_PROJECT) if BQ_PROJECT else storage.Client()\n",
        "\n",
        "print(f\"✓ Clients initialized\")\n",
        "print(f\"  Project: {bq_client.project}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading CSV from GCS...\n",
            "✓ CSV loaded successfully:\n",
            "  Rows: 39\n",
            "  Columns: ['__kp_Survey', '_kf_Site', 'SurveyYear', 'SurveyDate', 'Surveyor1']\n",
            "\n",
            "First few rows:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>__kp_Survey</th>\n",
              "      <th>_kf_Site</th>\n",
              "      <th>SurveyYear</th>\n",
              "      <th>SurveyDate</th>\n",
              "      <th>Surveyor1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B45700C5-D391-4679-8579-217DCB1385A2</td>\n",
              "      <td>227</td>\n",
              "      <td>2025</td>\n",
              "      <td>5/21/25</td>\n",
              "      <td>MLS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C0BD2A75-FF0B-48DC-BB9D-941267BF5838</td>\n",
              "      <td>190</td>\n",
              "      <td>2025</td>\n",
              "      <td>5/21/25</td>\n",
              "      <td>MLS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38A8FE64-8769-474C-BC25-01CBF006BFCC</td>\n",
              "      <td>331</td>\n",
              "      <td>2025</td>\n",
              "      <td>5/22/25</td>\n",
              "      <td>MLS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>147224CA-F0FC-4E02-B2DE-8B17F5553B29</td>\n",
              "      <td>45</td>\n",
              "      <td>2025</td>\n",
              "      <td>5/26/25</td>\n",
              "      <td>MLS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CD7E5294-F7D8-4CD6-B35A-EDB356A88A73</td>\n",
              "      <td>165</td>\n",
              "      <td>2025</td>\n",
              "      <td>5/26/25</td>\n",
              "      <td>MLS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            __kp_Survey  _kf_Site  SurveyYear SurveyDate  \\\n",
              "0  B45700C5-D391-4679-8579-217DCB1385A2       227        2025    5/21/25   \n",
              "1  C0BD2A75-FF0B-48DC-BB9D-941267BF5838       190        2025    5/21/25   \n",
              "2  38A8FE64-8769-474C-BC25-01CBF006BFCC       331        2025    5/22/25   \n",
              "3  147224CA-F0FC-4E02-B2DE-8B17F5553B29        45        2025    5/26/25   \n",
              "4  CD7E5294-F7D8-4CD6-B35A-EDB356A88A73       165        2025    5/26/25   \n",
              "\n",
              "  Surveyor1  \n",
              "0       MLS  \n",
              "1       MLS  \n",
              "2       MLS  \n",
              "3       MLS  \n",
              "4       MLS  "
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Read CSV from GCS (new data)\n",
        "print(\"Reading CSV from GCS...\")\n",
        "df_new = pd.read_csv(GCS_CSV_URL)\n",
        "\n",
        "print(f\"✓ CSV loaded successfully:\")\n",
        "print(f\"  Rows: {len(df_new)}\")\n",
        "print(f\"  Columns: {list(df_new.columns)}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "df_new.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transform CSV Data\n",
        "\n",
        "Apply schema transformations to match BigQuery table:\n",
        "- Rename columns to match destination schema\n",
        "- Convert date format from mm/dd/yyyy to ISO format (YYYY-MM-DD)\n",
        "- Create `survey_sequence` variable from `year` (2011 and 2012 → \"2011-12\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Column mapping:\n",
            "  __kp_Survey          → survey_ID\n",
            "  _kf_Site             → grid_point\n",
            "  SurveyYear           → year\n",
            "  SurveyDate           → date\n",
            "  Surveyor1            → surveyor\n"
          ]
        }
      ],
      "source": [
        "# Define column mapping from CSV to BigQuery\n",
        "column_mapping = {\n",
        "    '__kp_Survey': 'survey_ID',\n",
        "    '_kf_Site': 'grid_point',\n",
        "    'SurveyYear': 'year',\n",
        "    'SurveyDate': 'date',\n",
        "    'Surveyor1': 'surveyor'\n",
        "}\n",
        "\n",
        "print(\"Column mapping:\")\n",
        "for csv_col, bq_col in column_mapping.items():\n",
        "    print(f\"  {csv_col:20s} → {bq_col}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ CSV columns match expected schema\n",
            "\n",
            "CSV columns: ['__kp_Survey', '_kf_Site', 'SurveyYear', 'SurveyDate', 'Surveyor1']\n"
          ]
        }
      ],
      "source": [
        "# Verify CSV columns match expected schema\n",
        "expected_csv_columns = set(column_mapping.keys())\n",
        "actual_csv_columns = set(df_new.columns)\n",
        "\n",
        "if actual_csv_columns == expected_csv_columns:\n",
        "    print(\"✓ CSV columns match expected schema\")\n",
        "else:\n",
        "    print(\"⚠ CSV column differences detected:\")\n",
        "    if actual_csv_columns - expected_csv_columns:\n",
        "        print(f\"  Unexpected columns: {actual_csv_columns - expected_csv_columns}\")\n",
        "    if expected_csv_columns - actual_csv_columns:\n",
        "        print(f\"  Missing columns: {expected_csv_columns - actual_csv_columns}\")\n",
        "    \n",
        "print(f\"\\nCSV columns: {list(df_new.columns)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Columns renamed\n",
            "  Transformed columns: ['survey_ID', 'grid_point', 'year', 'date', 'surveyor']\n"
          ]
        }
      ],
      "source": [
        "# Apply transformation: rename columns\n",
        "df_transformed = df_new.copy()\n",
        "df_transformed = df_transformed.rename(columns=column_mapping)\n",
        "\n",
        "print(\"✓ Columns renamed\")\n",
        "print(f\"  Transformed columns: {list(df_transformed.columns)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Date format converted to date type\n",
            "  Sample dates: [datetime.date(2025, 5, 21), datetime.date(2025, 5, 21), datetime.date(2025, 5, 22), datetime.date(2025, 5, 26), datetime.date(2025, 5, 26)]\n"
          ]
        }
      ],
      "source": [
        "# Convert date from m/d/yy to proper datetime/date format\n",
        "# Explicitly specify format to avoid parsing warnings and ensure consistency\n",
        "# Note: %y handles 2-digit years (00-68 = 2000-2068, 69-99 = 1969-1999)\n",
        "df_transformed['date'] = pd.to_datetime(df_transformed['date'], format='%m/%d/%y').dt.date\n",
        "\n",
        "print(\"✓ Date format converted to date type\")\n",
        "print(f\"  Sample dates: {df_transformed['date'].head().tolist()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Created survey_sequence variable\n",
            "\n",
            "Survey sequence mapping:\n",
            "  Year 2025 → '2025' (39 records)\n"
          ]
        }
      ],
      "source": [
        "# Create survey_sequence variable from year\n",
        "# Recode 2011 and 2012 to \"2011-12\", leave all other years as strings\n",
        "def create_survey_sequence(year):\n",
        "    if year in [2011, 2012]:\n",
        "        return \"2011-12\"\n",
        "    else:\n",
        "        return str(year)\n",
        "\n",
        "df_transformed['survey_sequence'] = df_transformed['year'].apply(create_survey_sequence)\n",
        "\n",
        "print(\"✓ Created survey_sequence variable\")\n",
        "print(f\"\\nSurvey sequence mapping:\")\n",
        "for year in sorted(df_transformed['year'].unique()):\n",
        "    seq = df_transformed[df_transformed['year'] == year]['survey_sequence'].iloc[0]\n",
        "    count = len(df_transformed[df_transformed['year'] == year])\n",
        "    print(f\"  Year {year} → '{seq}' ({count} records)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transformed Data Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 39 entries, 0 to 38\n",
            "Data columns (total 6 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   survey_ID        39 non-null     object\n",
            " 1   grid_point       39 non-null     int64 \n",
            " 2   year             39 non-null     int64 \n",
            " 3   date             39 non-null     object\n",
            " 4   surveyor         39 non-null     object\n",
            " 5   survey_sequence  39 non-null     object\n",
            "dtypes: int64(2), object(4)\n",
            "memory usage: 2.0+ KB\n",
            "\n",
            "Transformed data preview:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survey_ID</th>\n",
              "      <th>grid_point</th>\n",
              "      <th>year</th>\n",
              "      <th>date</th>\n",
              "      <th>surveyor</th>\n",
              "      <th>survey_sequence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B45700C5-D391-4679-8579-217DCB1385A2</td>\n",
              "      <td>227</td>\n",
              "      <td>2025</td>\n",
              "      <td>2025-05-21</td>\n",
              "      <td>MLS</td>\n",
              "      <td>2025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C0BD2A75-FF0B-48DC-BB9D-941267BF5838</td>\n",
              "      <td>190</td>\n",
              "      <td>2025</td>\n",
              "      <td>2025-05-21</td>\n",
              "      <td>MLS</td>\n",
              "      <td>2025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38A8FE64-8769-474C-BC25-01CBF006BFCC</td>\n",
              "      <td>331</td>\n",
              "      <td>2025</td>\n",
              "      <td>2025-05-22</td>\n",
              "      <td>MLS</td>\n",
              "      <td>2025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>147224CA-F0FC-4E02-B2DE-8B17F5553B29</td>\n",
              "      <td>45</td>\n",
              "      <td>2025</td>\n",
              "      <td>2025-05-26</td>\n",
              "      <td>MLS</td>\n",
              "      <td>2025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CD7E5294-F7D8-4CD6-B35A-EDB356A88A73</td>\n",
              "      <td>165</td>\n",
              "      <td>2025</td>\n",
              "      <td>2025-05-26</td>\n",
              "      <td>MLS</td>\n",
              "      <td>2025</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              survey_ID  grid_point  year        date  \\\n",
              "0  B45700C5-D391-4679-8579-217DCB1385A2         227  2025  2025-05-21   \n",
              "1  C0BD2A75-FF0B-48DC-BB9D-941267BF5838         190  2025  2025-05-21   \n",
              "2  38A8FE64-8769-474C-BC25-01CBF006BFCC         331  2025  2025-05-22   \n",
              "3  147224CA-F0FC-4E02-B2DE-8B17F5553B29          45  2025  2025-05-26   \n",
              "4  CD7E5294-F7D8-4CD6-B35A-EDB356A88A73         165  2025  2025-05-26   \n",
              "\n",
              "  surveyor survey_sequence  \n",
              "0      MLS            2025  \n",
              "1      MLS            2025  \n",
              "2      MLS            2025  \n",
              "3      MLS            2025  \n",
              "4      MLS            2025  "
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display transformed data info\n",
        "print(\"Transformed Data Info:\")\n",
        "df_transformed.info()\n",
        "print(f\"\\nTransformed data preview:\")\n",
        "df_transformed.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Read Existing BigQuery Table\n",
        "\n",
        "Load the current data from BigQuery to compare with the new data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading existing data from mpg-data-warehouse.vegetation_point_intercept_gridVeg.gridVeg_survey_metadata...\n",
            "✓ Existing table loaded:\n",
            "  Rows: 1684\n",
            "  Columns: ['survey_ID', 'grid_point', 'year', 'date', 'survey_sequence', 'surveyor']\n",
            "\n",
            "Existing data preview:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survey_ID</th>\n",
              "      <th>grid_point</th>\n",
              "      <th>year</th>\n",
              "      <th>date</th>\n",
              "      <th>survey_sequence</th>\n",
              "      <th>surveyor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>138</td>\n",
              "      <td>61</td>\n",
              "      <td>2010</td>\n",
              "      <td>2010-08-27</td>\n",
              "      <td>2010</td>\n",
              "      <td>EAR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>139</td>\n",
              "      <td>60</td>\n",
              "      <td>2010</td>\n",
              "      <td>2010-08-27</td>\n",
              "      <td>2010</td>\n",
              "      <td>EAR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>135</td>\n",
              "      <td>52</td>\n",
              "      <td>2010</td>\n",
              "      <td>2010-08-27</td>\n",
              "      <td>2010</td>\n",
              "      <td>EAR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>134</td>\n",
              "      <td>51</td>\n",
              "      <td>2010</td>\n",
              "      <td>2010-08-27</td>\n",
              "      <td>2010</td>\n",
              "      <td>EAR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>137</td>\n",
              "      <td>62</td>\n",
              "      <td>2010</td>\n",
              "      <td>2010-08-27</td>\n",
              "      <td>2010</td>\n",
              "      <td>EAR</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  survey_ID  grid_point  year        date survey_sequence surveyor\n",
              "0       138          61  2010  2010-08-27            2010      EAR\n",
              "1       139          60  2010  2010-08-27            2010      EAR\n",
              "2       135          52  2010  2010-08-27            2010      EAR\n",
              "3       134          51  2010  2010-08-27            2010      EAR\n",
              "4       137          62  2010  2010-08-27            2010      EAR"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Read existing data from BigQuery\n",
        "print(f\"Reading existing data from {BQ_TABLE_ID}...\")\n",
        "query = f\"SELECT * FROM `{BQ_TABLE_ID}`\"\n",
        "\n",
        "try:\n",
        "    df_existing = bq_client.query(query).to_dataframe()\n",
        "    print(f\"✓ Existing table loaded:\")\n",
        "    print(f\"  Rows: {len(df_existing)}\")\n",
        "    print(f\"  Columns: {list(df_existing.columns)}\")\n",
        "    print(f\"\\nExisting data preview:\")\n",
        "    display(df_existing.head())\n",
        "except Exception as e:\n",
        "    print(f\"⚠ Error reading table: {e}\")\n",
        "    print(\"  This may be expected if the table doesn't exist yet.\")\n",
        "    df_existing = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Existing Data Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1684 entries, 0 to 1683\n",
            "Data columns (total 6 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   survey_ID        1684 non-null   object\n",
            " 1   grid_point       1684 non-null   Int64 \n",
            " 2   year             1684 non-null   Int64 \n",
            " 3   date             1684 non-null   dbdate\n",
            " 4   survey_sequence  1684 non-null   object\n",
            " 5   surveyor         1684 non-null   object\n",
            "dtypes: Int64(2), dbdate(1), object(3)\n",
            "memory usage: 82.4+ KB\n"
          ]
        }
      ],
      "source": [
        "# Display existing data info (if available)\n",
        "if df_existing is not None:\n",
        "    print(\"Existing Data Info:\")\n",
        "    df_existing.info()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compare New vs Existing Data\n",
        "\n",
        "Identify which rows in the new data are not already in the existing table.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Comparison Summary ===\n",
            "\n",
            "Row count:\n",
            "  Existing: 1684\n",
            "  New CSV:  39\n",
            "\n",
            "✓ Columns match (6 columns)\n",
            "\n",
            "Columns: ['survey_ID', 'grid_point', 'year', 'date', 'surveyor', 'survey_sequence']\n"
          ]
        }
      ],
      "source": [
        "# Compare datasets\n",
        "if df_existing is not None:\n",
        "    print(\"=== Comparison Summary ===\\n\")\n",
        "    \n",
        "    # Row count comparison\n",
        "    print(f\"Row count:\")\n",
        "    print(f\"  Existing: {len(df_existing)}\")\n",
        "    print(f\"  New CSV:  {len(df_transformed)}\")\n",
        "    \n",
        "    # Column comparison\n",
        "    existing_cols = set(df_existing.columns)\n",
        "    new_cols = set(df_transformed.columns)\n",
        "    \n",
        "    if existing_cols == new_cols:\n",
        "        print(f\"\\n✓ Columns match ({len(new_cols)} columns)\")\n",
        "    else:\n",
        "        print(\"\\n⚠ Column differences detected:\")\n",
        "        if new_cols - existing_cols:\n",
        "            print(f\"  New columns: {new_cols - existing_cols}\")\n",
        "        if existing_cols - new_cols:\n",
        "            print(f\"  Missing columns: {existing_cols - new_cols}\")\n",
        "    \n",
        "    print(f\"\\nColumns: {list(df_transformed.columns)}\")\n",
        "else:\n",
        "    print(\"No existing data to compare - this will be a new table creation.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Found 39 new records to append\n",
            "\n",
            "New records by year:\n",
            "  2025: 39 records\n",
            "\n",
            "Sample of new records:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survey_ID</th>\n",
              "      <th>grid_point</th>\n",
              "      <th>year</th>\n",
              "      <th>date</th>\n",
              "      <th>surveyor</th>\n",
              "      <th>survey_sequence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B45700C5-D391-4679-8579-217DCB1385A2</td>\n",
              "      <td>227</td>\n",
              "      <td>2025</td>\n",
              "      <td>2025-05-21</td>\n",
              "      <td>MLS</td>\n",
              "      <td>2025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C0BD2A75-FF0B-48DC-BB9D-941267BF5838</td>\n",
              "      <td>190</td>\n",
              "      <td>2025</td>\n",
              "      <td>2025-05-21</td>\n",
              "      <td>MLS</td>\n",
              "      <td>2025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38A8FE64-8769-474C-BC25-01CBF006BFCC</td>\n",
              "      <td>331</td>\n",
              "      <td>2025</td>\n",
              "      <td>2025-05-22</td>\n",
              "      <td>MLS</td>\n",
              "      <td>2025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>147224CA-F0FC-4E02-B2DE-8B17F5553B29</td>\n",
              "      <td>45</td>\n",
              "      <td>2025</td>\n",
              "      <td>2025-05-26</td>\n",
              "      <td>MLS</td>\n",
              "      <td>2025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CD7E5294-F7D8-4CD6-B35A-EDB356A88A73</td>\n",
              "      <td>165</td>\n",
              "      <td>2025</td>\n",
              "      <td>2025-05-26</td>\n",
              "      <td>MLS</td>\n",
              "      <td>2025</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              survey_ID  grid_point  year        date  \\\n",
              "0  B45700C5-D391-4679-8579-217DCB1385A2         227  2025  2025-05-21   \n",
              "1  C0BD2A75-FF0B-48DC-BB9D-941267BF5838         190  2025  2025-05-21   \n",
              "2  38A8FE64-8769-474C-BC25-01CBF006BFCC         331  2025  2025-05-22   \n",
              "3  147224CA-F0FC-4E02-B2DE-8B17F5553B29          45  2025  2025-05-26   \n",
              "4  CD7E5294-F7D8-4CD6-B35A-EDB356A88A73         165  2025  2025-05-26   \n",
              "\n",
              "  surveyor survey_sequence  \n",
              "0      MLS            2025  \n",
              "1      MLS            2025  \n",
              "2      MLS            2025  \n",
              "3      MLS            2025  \n",
              "4      MLS            2025  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Identify new records (not in existing table)\n",
        "# Use survey_ID as the unique identifier\n",
        "if df_existing is not None:\n",
        "    existing_ids = set(df_existing['survey_ID'])\n",
        "    new_ids = set(df_transformed['survey_ID'])\n",
        "    \n",
        "    # Find records in new data that aren't in existing\n",
        "    ids_to_append = new_ids - existing_ids\n",
        "    \n",
        "    if ids_to_append:\n",
        "        df_to_append = df_transformed[df_transformed['survey_ID'].isin(ids_to_append)].copy()\n",
        "        print(f\"✓ Found {len(df_to_append)} new records to append\")\n",
        "        \n",
        "        # Show year breakdown of new records\n",
        "        print(f\"\\nNew records by year:\")\n",
        "        year_counts = df_to_append['year'].value_counts().sort_index()\n",
        "        for year, count in year_counts.items():\n",
        "            print(f\"  {year}: {count} records\")\n",
        "        \n",
        "        print(f\"\\nSample of new records:\")\n",
        "        display(df_to_append.head())\n",
        "    else:\n",
        "        df_to_append = None\n",
        "        print(\"⚠ No new records found - all survey_IDs already exist in table\")\n",
        "        print(\"  Nothing to append.\")\n",
        "    \n",
        "    # Check for any duplicates\n",
        "    duplicate_ids = existing_ids & new_ids\n",
        "    if duplicate_ids:\n",
        "        print(f\"\\n⚠ Warning: {len(duplicate_ids)} survey_IDs already exist in table\")\n",
        "        print(f\"  These will be skipped during append.\")\n",
        "        if len(duplicate_ids) <= 10:\n",
        "            print(f\"  Duplicate IDs: {list(duplicate_ids)[:10]}\")\n",
        "else:\n",
        "    # No existing table, so all records are new\n",
        "    df_to_append = df_transformed.copy()\n",
        "    print(f\"✓ No existing table - will create new table with {len(df_to_append)} records\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Backup Existing Table\n",
        "\n",
        "Before making any changes, create a backup of the existing table to GCS.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Backup existing table to GCS\n",
        "if df_existing is not None and BACKUP_BUCKET and df_to_append is not None:\n",
        "    # Generate backup path with timestamp\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    backup_path = f\"gs://{BACKUP_BUCKET}/{BACKUP_PREFIX}/{timestamp}/*.csv\"\n",
        "    \n",
        "    print(f\"Creating backup of existing table...\")\n",
        "    print(f\"  Destination: {backup_path}\")\n",
        "    \n",
        "    # Export table to GCS\n",
        "    extract_job = bq_client.extract_table(\n",
        "        BQ_TABLE_ID,\n",
        "        backup_path,\n",
        "        location=\"US\"\n",
        "    )\n",
        "    \n",
        "    extract_job.result()  # Wait for job to complete\n",
        "    \n",
        "    print(f\"✓ Backup completed successfully\")\n",
        "    print(f\"  Files: {backup_path}\")\n",
        "elif df_existing is None:\n",
        "    print(\"⚠ No existing table to backup (table doesn't exist yet)\")\n",
        "elif not BACKUP_BUCKET:\n",
        "    print(\"⚠ Backup bucket not configured in config.yml\")\n",
        "    print(\"  Set 'gridveg_survey_metadata.gcs.backup_bucket' to enable automatic backups\")\n",
        "elif df_to_append is None:\n",
        "    print(\"⚠ No new records to append, skipping backup\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Append New Records to BigQuery\n",
        "\n",
        "⚠️ **IMPORTANT**: This will APPEND new rows to the existing table (not replace).\n",
        "\n",
        "Review the comparison above before proceeding.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "APPENDING TO BIGQUERY TABLE\n",
            "============================================================\n",
            "\n",
            "Table: mpg-data-warehouse.vegetation_point_intercept_gridVeg.gridVeg_survey_metadata\n",
            "Rows to append: 39\n",
            "Mode: WRITE_APPEND (add to existing table)\n",
            "\n",
            "Starting append at 2025-10-30 12:36:56...\n",
            "\n",
            "✓ Append completed at 2025-10-30 12:37:01\n",
            "  Rows appended: 39\n",
            "  Job ID: 64b79468-d54c-4408-b7af-b3c4b71503b5\n"
          ]
        }
      ],
      "source": [
        "# Append new records to BigQuery\n",
        "if df_to_append is not None and len(df_to_append) > 0:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"APPENDING TO BIGQUERY TABLE\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"\\nTable: {BQ_TABLE_ID}\")\n",
        "    print(f\"Rows to append: {len(df_to_append)}\")\n",
        "    print(f\"Mode: WRITE_APPEND (add to existing table)\")\n",
        "    print(f\"\\nStarting append at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}...\")\n",
        "    \n",
        "    # Configure job to append to existing table\n",
        "    job_config = bigquery.LoadJobConfig(\n",
        "        write_disposition=\"WRITE_APPEND\"  # Append to existing table\n",
        "    )\n",
        "    \n",
        "    # Load dataframe to BigQuery\n",
        "    load_job = bq_client.load_table_from_dataframe(\n",
        "        df_to_append,\n",
        "        BQ_TABLE_ID,\n",
        "        job_config=job_config\n",
        "    )\n",
        "    \n",
        "    # Wait for job to complete\n",
        "    load_job.result()\n",
        "    \n",
        "    print(f\"\\n✓ Append completed at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "    print(f\"  Rows appended: {load_job.output_rows}\")\n",
        "    print(f\"  Job ID: {load_job.job_id}\")\n",
        "else:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"NO RECORDS TO APPEND\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"\\nNo new records found or no records to append.\")\n",
        "    print(\"Table remains unchanged.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Verify Append\n",
        "\n",
        "Read back the table to verify the append was successful.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Verifying append...\n",
            "\n",
            "✓ Verification complete\n",
            "  Rows in table: 1723\n",
            "  Columns: ['survey_ID', 'grid_point', 'year', 'date', 'survey_sequence', 'surveyor']\n",
            "\n",
            "Records by year:\n",
            "  2010: 227 records\n",
            "  2011: 380 records\n",
            "  2012: 196 records\n",
            "  2013: 33 records\n",
            "  2015: 59 records\n",
            "  2016: 571 records\n",
            "  2017: 6 records\n",
            "  2021: 93 records\n",
            "  2022: 50 records\n",
            "  2023: 36 records\n",
            "  2024: 33 records\n",
            "  2025: 39 records\n",
            "\n",
            "Updated table preview:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survey_ID</th>\n",
              "      <th>grid_point</th>\n",
              "      <th>year</th>\n",
              "      <th>date</th>\n",
              "      <th>survey_sequence</th>\n",
              "      <th>surveyor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1713</th>\n",
              "      <td>855E1EDA-25B0-4D26-B93D-55B5DA65B12B</td>\n",
              "      <td>575</td>\n",
              "      <td>2024</td>\n",
              "      <td>2024-06-04</td>\n",
              "      <td>2024</td>\n",
              "      <td>MLS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1714</th>\n",
              "      <td>2F81159A-9EFD-4B21-9FA6-909EE12322EB</td>\n",
              "      <td>181</td>\n",
              "      <td>2024</td>\n",
              "      <td>2024-06-05</td>\n",
              "      <td>2024</td>\n",
              "      <td>MLS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1715</th>\n",
              "      <td>907893F5-C3BC-44DC-B4F9-89ECF42889FC</td>\n",
              "      <td>44</td>\n",
              "      <td>2024</td>\n",
              "      <td>2024-06-05</td>\n",
              "      <td>2024</td>\n",
              "      <td>MLS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1716</th>\n",
              "      <td>6C62D7D1-E82E-48A2-B9A2-6104F44C47CB</td>\n",
              "      <td>40</td>\n",
              "      <td>2024</td>\n",
              "      <td>2024-06-05</td>\n",
              "      <td>2024</td>\n",
              "      <td>MLS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1717</th>\n",
              "      <td>82438031-83AF-4529-A22A-7186B4A41ED6</td>\n",
              "      <td>306</td>\n",
              "      <td>2024</td>\n",
              "      <td>2024-06-06</td>\n",
              "      <td>2024</td>\n",
              "      <td>MLS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1718</th>\n",
              "      <td>E1B65DEA-1BFC-40A0-9B35-CC8E0FA4E8A2</td>\n",
              "      <td>571</td>\n",
              "      <td>2024</td>\n",
              "      <td>2024-06-06</td>\n",
              "      <td>2024</td>\n",
              "      <td>MLS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1719</th>\n",
              "      <td>A66F7709-4260-482F-901D-3F060F3DE97B</td>\n",
              "      <td>405</td>\n",
              "      <td>2024</td>\n",
              "      <td>2024-07-03</td>\n",
              "      <td>2024</td>\n",
              "      <td>MLS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1720</th>\n",
              "      <td>51586925-D83F-495F-9ADA-A7843BCC2098</td>\n",
              "      <td>570</td>\n",
              "      <td>2024</td>\n",
              "      <td>2024-07-04</td>\n",
              "      <td>2024</td>\n",
              "      <td>MLS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1721</th>\n",
              "      <td>E71C66DF-7C7A-4834-8034-5731CDDE84C9</td>\n",
              "      <td>70</td>\n",
              "      <td>2024</td>\n",
              "      <td>2024-07-10</td>\n",
              "      <td>2024</td>\n",
              "      <td>MLS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1722</th>\n",
              "      <td>11BCE714-4E58-4F75-8238-323BB5D2616C</td>\n",
              "      <td>420</td>\n",
              "      <td>2024</td>\n",
              "      <td>2024-07-11</td>\n",
              "      <td>2024</td>\n",
              "      <td>MLS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 survey_ID  grid_point  year        date  \\\n",
              "1713  855E1EDA-25B0-4D26-B93D-55B5DA65B12B         575  2024  2024-06-04   \n",
              "1714  2F81159A-9EFD-4B21-9FA6-909EE12322EB         181  2024  2024-06-05   \n",
              "1715  907893F5-C3BC-44DC-B4F9-89ECF42889FC          44  2024  2024-06-05   \n",
              "1716  6C62D7D1-E82E-48A2-B9A2-6104F44C47CB          40  2024  2024-06-05   \n",
              "1717  82438031-83AF-4529-A22A-7186B4A41ED6         306  2024  2024-06-06   \n",
              "1718  E1B65DEA-1BFC-40A0-9B35-CC8E0FA4E8A2         571  2024  2024-06-06   \n",
              "1719  A66F7709-4260-482F-901D-3F060F3DE97B         405  2024  2024-07-03   \n",
              "1720  51586925-D83F-495F-9ADA-A7843BCC2098         570  2024  2024-07-04   \n",
              "1721  E71C66DF-7C7A-4834-8034-5731CDDE84C9          70  2024  2024-07-10   \n",
              "1722  11BCE714-4E58-4F75-8238-323BB5D2616C         420  2024  2024-07-11   \n",
              "\n",
              "     survey_sequence surveyor  \n",
              "1713            2024      MLS  \n",
              "1714            2024      MLS  \n",
              "1715            2024      MLS  \n",
              "1716            2024      MLS  \n",
              "1717            2024      MLS  \n",
              "1718            2024      MLS  \n",
              "1719            2024      MLS  \n",
              "1720            2024      MLS  \n",
              "1721            2024      MLS  \n",
              "1722            2024      MLS  "
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Read updated table\n",
        "print(\"Verifying append...\")\n",
        "query = f\"SELECT * FROM `{BQ_TABLE_ID}`\"\n",
        "df_updated = bq_client.query(query).to_dataframe()\n",
        "\n",
        "print(f\"\\n✓ Verification complete\")\n",
        "print(f\"  Rows in table: {len(df_updated)}\")\n",
        "print(f\"  Columns: {list(df_updated.columns)}\")\n",
        "\n",
        "# Show records by year\n",
        "print(f\"\\nRecords by year:\")\n",
        "year_counts = df_updated['year'].value_counts().sort_index()\n",
        "for year, count in year_counts.items():\n",
        "    print(f\"  {year}: {count} records\")\n",
        "\n",
        "print(f\"\\nUpdated table preview:\")\n",
        "df_updated.tail(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data integrity check:\n",
            "  Previous rows:   1684\n",
            "  Rows appended:   39\n",
            "  Expected total:  1723\n",
            "  Actual total:    1723\n",
            "\n",
            "✓ Row count verified - all 39 new rows successfully appended\n"
          ]
        }
      ],
      "source": [
        "# Verify row counts\n",
        "if df_to_append is not None and len(df_to_append) > 0:\n",
        "    expected_rows = len(df_existing) + len(df_to_append) if df_existing is not None else len(df_to_append)\n",
        "    actual_rows = len(df_updated)\n",
        "    \n",
        "    print(\"Data integrity check:\")\n",
        "    if df_existing is not None:\n",
        "        print(f\"  Previous rows:   {len(df_existing)}\")\n",
        "        print(f\"  Rows appended:   {len(df_to_append)}\")\n",
        "        print(f\"  Expected total:  {expected_rows}\")\n",
        "        print(f\"  Actual total:    {actual_rows}\")\n",
        "    else:\n",
        "        print(f\"  Rows written:    {len(df_to_append)}\")\n",
        "        print(f\"  Rows in table:   {actual_rows}\")\n",
        "    \n",
        "    if expected_rows == actual_rows:\n",
        "        print(f\"\\n✓ Row count verified - all {len(df_to_append)} new rows successfully appended\")\n",
        "    else:\n",
        "        print(f\"\\n⚠ Row count mismatch!\")\n",
        "        print(f\"  Expected: {expected_rows}\")\n",
        "        print(f\"  Actual:   {actual_rows}\")\n",
        "        print(f\"  Difference: {actual_rows - expected_rows}\")\n",
        "else:\n",
        "    print(\"No new records were appended.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary Report\n",
        "\n",
        "Complete summary of the append operation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "GRIDVEG SURVEY METADATA APPEND SUMMARY\n",
            "============================================================\n",
            "\n",
            "📅 Timestamp: 2025-10-30 12:37:24\n",
            "\n",
            "📂 Source:\n",
            "  CSV: 2025-09-18_gridVeg_survey_metadata_SOURCE.csv\n",
            "  Location: gs://mpg-data-warehouse/gridVeg/src/2025\n",
            "\n",
            "🎯 Target:\n",
            "  Table: mpg-data-warehouse.vegetation_point_intercept_gridVeg.gridVeg_survey_metadata\n",
            "  Project: mpg-data-warehouse\n",
            "\n",
            "📊 Data Changes:\n",
            "  Previous rows: 1684\n",
            "  New rows:      1723\n",
            "  Rows appended: +39\n",
            "\n",
            "  Appended records by year:\n",
            "    2025: 39 records\n",
            "\n",
            "🔄 Transformations Applied:\n",
            "  ✓ Renamed 5 columns to match BigQuery schema\n",
            "  ✓ Converted date format to ISO (YYYY-MM-DD)\n",
            "  ✓ Created survey_sequence variable (2011/2012 → 2011-12)\n",
            "\n",
            "💾 Backup:\n",
            "  Location: gs://mpg-data-warehouse/gridVeg/bak/\n",
            "  Status: ✓ Created before append\n",
            "\n",
            "✅ Append completed successfully!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Generate summary report\n",
        "print(\"=\" * 60)\n",
        "print(\"GRIDVEG SURVEY METADATA APPEND SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\n📅 Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "print(f\"\\n📂 Source:\")\n",
        "print(f\"  CSV: {GCS_CSV_URL.split('/')[-1]}\")\n",
        "print(f\"  Location: {'/'.join(GCS_CSV_URL.split('/')[:-1])}\")\n",
        "\n",
        "print(f\"\\n🎯 Target:\")\n",
        "print(f\"  Table: {BQ_TABLE_ID}\")\n",
        "print(f\"  Project: {bq_client.project}\")\n",
        "\n",
        "print(f\"\\n📊 Data Changes:\")\n",
        "if df_existing is not None:\n",
        "    print(f\"  Previous rows: {len(df_existing)}\")\n",
        "    print(f\"  New rows:      {len(df_updated)}\")\n",
        "    print(f\"  Rows appended: {len(df_updated) - len(df_existing):+d}\")\n",
        "    \n",
        "    if df_to_append is not None and len(df_to_append) > 0:\n",
        "        print(f\"\\n  Appended records by year:\")\n",
        "        year_counts = df_to_append['year'].value_counts().sort_index()\n",
        "        for year, count in year_counts.items():\n",
        "            print(f\"    {year}: {count} records\")\n",
        "else:\n",
        "    print(f\"  New table created with {len(df_updated)} rows\")\n",
        "\n",
        "print(f\"\\n🔄 Transformations Applied:\")\n",
        "print(f\"  ✓ Renamed {len(column_mapping)} columns to match BigQuery schema\")\n",
        "print(f\"  ✓ Converted date format to ISO (YYYY-MM-DD)\")\n",
        "print(f\"  ✓ Created survey_sequence variable (2011/2012 → 2011-12)\")\n",
        "\n",
        "if BACKUP_BUCKET and df_existing is not None and df_to_append is not None and len(df_to_append) > 0:\n",
        "    print(f\"\\n💾 Backup:\")\n",
        "    print(f\"  Location: gs://{BACKUP_BUCKET}/{BACKUP_PREFIX}/\")\n",
        "    print(f\"  Status: ✓ Created before append\")\n",
        "\n",
        "if df_to_append is not None and len(df_to_append) > 0:\n",
        "    print(f\"\\n✅ Append completed successfully!\")\n",
        "else:\n",
        "    print(f\"\\n✅ No changes needed - table is up to date!\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Rollback Instructions (If Needed)\n",
        "\n",
        "If you need to rollback to the previous version, use the backup created at the beginning of this notebook.\n",
        "\n",
        "```python\n",
        "# To rollback, first delete the appended rows:\n",
        "# df_rollback = df_updated[~df_updated['survey_ID'].isin(df_to_append['survey_ID'])]\n",
        "# job_config = bigquery.LoadJobConfig(write_disposition=\"WRITE_TRUNCATE\")\n",
        "# bq_client.load_table_from_dataframe(df_rollback, BQ_TABLE_ID, job_config=job_config)\n",
        "\n",
        "# Or restore from backup:\n",
        "# backup_path = \"gs://BACKUP_BUCKET/BACKUP_PREFIX/TIMESTAMP/*.csv\"\n",
        "# df_backup = pd.read_csv(backup_path)\n",
        "# job_config = bigquery.LoadJobConfig(write_disposition=\"WRITE_TRUNCATE\")\n",
        "# bq_client.load_table_from_dataframe(df_backup, BQ_TABLE_ID, job_config=job_config)\n",
        "```\n",
        "\n",
        "The backup location was printed in the backup cell above.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "gcloud",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
